{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/10], Loss: 0.3876, Time elapsed: 166.93 seconds\n",
      "Epoch [2/10], Loss: 0.0443, Time elapsed: 215.32 seconds\n",
      "Epoch [3/10], Loss: 0.0159, Time elapsed: 234.99 seconds\n",
      "Epoch [4/10], Loss: 0.0077, Time elapsed: 293.57 seconds\n",
      "Epoch [5/10], Loss: 0.0059, Time elapsed: 251.94 seconds\n",
      "Epoch [6/10], Loss: 0.0068, Time elapsed: 221.33 seconds\n",
      "Epoch [7/10], Loss: 0.0083, Time elapsed: 272.43 seconds\n",
      "Epoch [8/10], Loss: 0.0016, Time elapsed: 279.28 seconds\n",
      "Epoch [9/10], Loss: 0.0002, Time elapsed: 265.09 seconds\n",
      "Epoch [10/10], Loss: 0.0001, Time elapsed: 237.29 seconds\n",
      "Training completed in: 2438.17 seconds\n",
      "Accuracy: 0.9976, Precision: 0.9978, Recall: 0.9978, F1 Score: 0.9978\n"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, confusion_matrix, ConfusionMatrixDisplay\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import torchvision.transforms as transforms\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from PIL import Image\n",
    "import os\n",
    "import math\n",
    "import seaborn as sns\n",
    "import time\n",
    "\n",
    "\n",
    "from kan_convolutional.KANLinear import KANLinear\n",
    "from kan_convolutional.KANConv import KAN_Convolutional_Layer\n",
    "from kan_convolutional import convolution \n",
    "\n",
    "import os\n",
    "from PIL import Image\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torchvision.transforms as transforms\n",
    "\n",
    "class Data_Class(Dataset):\n",
    "    def __init__(self, root_dirs, transform=None):\n",
    "        self.transform = transform\n",
    "        self.image_files = []\n",
    "        self.labels = []\n",
    "        self.class_names = []\n",
    "\n",
    "        for root_dir in root_dirs:\n",
    "            for label, subfolder in enumerate(os.listdir(root_dir)):\n",
    "                subfolder_path = os.path.join(root_dir, subfolder)\n",
    "                if os.path.isdir(subfolder_path):\n",
    "                    if subfolder not in self.class_names:\n",
    "                        self.class_names.append(subfolder)\n",
    "                    label = self.class_names.index(subfolder)\n",
    "                    for img_file in os.listdir(subfolder_path):\n",
    "                        if img_file.endswith('.png'):\n",
    "                            self.image_files.append(os.path.join(subfolder_path, img_file))\n",
    "                            self.labels.append(label)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.image_files)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        img_name = self.image_files[idx]\n",
    "        image = Image.open(img_name).convert('L')\n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "        label = self.labels[idx]\n",
    "        return image, label\n",
    "\n",
    "    def get_class_names(self):\n",
    "        return self.class_names\n",
    "\n",
    "root_dirs = [\n",
    "    \"aug\"\n",
    "]\n",
    "\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize((64, 64)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.5,), (0.5,))\n",
    "])\n",
    "\n",
    "dataset = Data_Class(root_dirs=root_dirs, transform=transform)\n",
    "train_size = int(0.8 * len(dataset))\n",
    "test_size = len(dataset) - train_size\n",
    "train_dataset, test_dataset = torch.utils.data.random_split(dataset, [train_size, test_size])\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=64, shuffle=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=64, shuffle=False)\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "class BasicResNetBlock(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels, stride=1):\n",
    "        super(BasicResNetBlock, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(in_channels, out_channels, kernel_size=3, stride=stride, padding=1)\n",
    "        self.bn1 = nn.BatchNorm2d(out_channels)\n",
    "        self.conv2 = nn.Conv2d(out_channels, out_channels, kernel_size=3, padding=1)\n",
    "        self.bn2 = nn.BatchNorm2d(out_channels)\n",
    "\n",
    "        self.skip_connection = nn.Sequential()\n",
    "        if stride != 1 or in_channels != out_channels:\n",
    "            self.skip_connection = nn.Sequential(\n",
    "                nn.Conv2d(in_channels, out_channels, kernel_size=1, stride=stride),\n",
    "                nn.BatchNorm2d(out_channels)\n",
    "            )\n",
    "\n",
    "    def forward(self, x):\n",
    "        residual = self.skip_connection(x)\n",
    "        x = F.relu(self.bn1(self.conv1(x)))\n",
    "        x = self.bn2(self.conv2(x))\n",
    "        x += residual\n",
    "        x = F.relu(x)\n",
    "        return x\n",
    "\n",
    "\n",
    "class SuperResidualKAN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(SuperResidualKAN, self).__init__()\n",
    "\n",
    "        # Replace Conv2d layers with ResNet blocks\n",
    "        self.resnet_block1 = BasicResNetBlock(1, 5)\n",
    "        self.resnet_block2 = BasicResNetBlock(5, 25)\n",
    "\n",
    "        self.maxpool = nn.MaxPool2d(kernel_size=(2, 2))\n",
    "\n",
    "        self.flatten = nn.Flatten()\n",
    "\n",
    "        self.kan1 = KANLinear(\n",
    "            in_features=6400,\n",
    "            out_features=256,\n",
    "            grid_size=10,\n",
    "            spline_order=3,\n",
    "            scale_noise=0.01,\n",
    "            scale_base=1,\n",
    "            scale_spline=1,\n",
    "            base_activation=nn.SiLU,\n",
    "            grid_eps=0.02,\n",
    "            grid_range=[0, 1]\n",
    "        )\n",
    "\n",
    "        self.kan2 = KANLinear(\n",
    "            in_features=256,\n",
    "            out_features=9,  # Adjust for number of classes\n",
    "            grid_size=10,\n",
    "            spline_order=3,\n",
    "            scale_noise=0.01,\n",
    "            scale_base=1,\n",
    "            scale_spline=1,\n",
    "            base_activation=nn.SiLU,\n",
    "            grid_eps=0.02,\n",
    "            grid_range=[0, 1]\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.resnet_block1(x)\n",
    "        x = self.maxpool(x)\n",
    "\n",
    "        x = self.resnet_block2(x)\n",
    "        x = self.maxpool(x)\n",
    "\n",
    "        x = self.flatten(x)\n",
    "\n",
    "        x = self.kan1(x)\n",
    "\n",
    "        x = self.kan2(x)\n",
    "\n",
    "        x = F.log_softmax(x, dim=1)\n",
    "\n",
    "        return x\n",
    "\n",
    "    \n",
    "model = SuperResidualKAN()\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "start_time = time.time()\n",
    "\n",
    "for epoch in range(10): \n",
    "    epoch_start_time = time.time()\n",
    "    model.train()\n",
    "    running_loss = 0.0\n",
    "    for images, labels in train_loader:\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(images)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        running_loss += loss.item()\n",
    "\n",
    "    epoch_time = time.time() - epoch_start_time\n",
    "    print(f'Epoch [{epoch + 1}/10], Loss: {running_loss / len(train_loader):.4f}, Time elapsed: {epoch_time:.2f} seconds')\n",
    "\n",
    "total_time = time.time() - start_time\n",
    "print(f\"Training completed in: {total_time:.2f} seconds\")\n",
    "\n",
    "model.eval()\n",
    "all_preds = []\n",
    "all_labels = []\n",
    "with torch.no_grad():\n",
    "    for images, labels in test_loader:\n",
    "        outputs = model(images)\n",
    "        _, preds = torch.max(outputs, 1)\n",
    "        all_preds.extend(preds.numpy())\n",
    "        all_labels.extend(labels.numpy())\n",
    "\n",
    "all_preds = np.array(all_preds)\n",
    "all_labels = np.array(all_labels)\n",
    "\n",
    "accuracy = accuracy_score(all_labels, all_preds)\n",
    "precision = precision_score(all_labels, all_preds, average='macro')\n",
    "recall = recall_score(all_labels, all_preds, average='macro')\n",
    "f1 = f1_score(all_labels, all_preds, average='macro')\n",
    "\n",
    "print(f'Accuracy: {accuracy:.4f}, Precision: {precision:.4f}, Recall: {recall:.4f}, F1 Score: {f1:.4f}')\n",
    "torch.save(model.state_dict(), 'super_kan_r_64x64.pth')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
