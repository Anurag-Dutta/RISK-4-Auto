{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/10], Loss: 1.1303, Time elapsed: 220.53 seconds\n",
      "Epoch [2/10], Loss: 0.5148, Time elapsed: 187.59 seconds\n",
      "Epoch [3/10], Loss: 0.2709, Time elapsed: 176.61 seconds\n",
      "Epoch [4/10], Loss: 0.1383, Time elapsed: 180.12 seconds\n",
      "Epoch [5/10], Loss: 0.0947, Time elapsed: 160.86 seconds\n",
      "Epoch [6/10], Loss: 0.1101, Time elapsed: 176.55 seconds\n",
      "Epoch [7/10], Loss: 0.0485, Time elapsed: 162.82 seconds\n",
      "Epoch [8/10], Loss: 0.0393, Time elapsed: 181.02 seconds\n",
      "Epoch [9/10], Loss: 0.0324, Time elapsed: 174.93 seconds\n",
      "Epoch [10/10], Loss: 0.0289, Time elapsed: 168.30 seconds\n",
      "Training completed in: 1789.33 seconds\n",
      "Accuracy: 0.9903, Precision: 0.9914, Recall: 0.9909, F1 Score: 0.9911\n"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, confusion_matrix, ConfusionMatrixDisplay\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import torchvision.transforms as transforms\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from PIL import Image\n",
    "import os\n",
    "import math\n",
    "import seaborn as sns\n",
    "import time\n",
    "\n",
    "\n",
    "from kan_convolutional.KANLinear import KANLinear\n",
    "from kan_convolutional.KANConv import KAN_Convolutional_Layer\n",
    "from kan_convolutional import convolution \n",
    "\n",
    "import os\n",
    "from PIL import Image\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torchvision.transforms as transforms\n",
    "\n",
    "class Data_Class(Dataset):\n",
    "    def __init__(self, root_dirs, transform=None):\n",
    "        self.transform = transform\n",
    "        self.image_files = []\n",
    "        self.labels = []\n",
    "        self.class_names = []\n",
    "\n",
    "        for root_dir in root_dirs:\n",
    "            for label, subfolder in enumerate(os.listdir(root_dir)):\n",
    "                subfolder_path = os.path.join(root_dir, subfolder)\n",
    "                if os.path.isdir(subfolder_path):\n",
    "                    if subfolder not in self.class_names:\n",
    "                        self.class_names.append(subfolder)\n",
    "                    label = self.class_names.index(subfolder)\n",
    "                    for img_file in os.listdir(subfolder_path):\n",
    "                        if img_file.endswith('.png'):\n",
    "                            self.image_files.append(os.path.join(subfolder_path, img_file))\n",
    "                            self.labels.append(label)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.image_files)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        img_name = self.image_files[idx]\n",
    "        image = Image.open(img_name).convert('L')\n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "        label = self.labels[idx]\n",
    "        return image, label\n",
    "\n",
    "    def get_class_names(self):\n",
    "        return self.class_names\n",
    "\n",
    "root_dirs = [\n",
    "    \"aug\"\n",
    "]\n",
    "\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize((64, 64)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.5,), (0.5,))\n",
    "])\n",
    "\n",
    "dataset = Data_Class(root_dirs=root_dirs, transform=transform)\n",
    "train_size = int(0.8 * len(dataset))\n",
    "test_size = len(dataset) - train_size\n",
    "train_dataset, test_dataset = torch.utils.data.random_split(dataset, [train_size, test_size])\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=64, shuffle=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=64, shuffle=False)\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "class SuperConvolutionalKAN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(SuperConvolutionalKAN, self).__init__()\n",
    "\n",
    "        self.conv1 = nn.Conv2d(1, 5, kernel_size=3, padding=1)\n",
    "        self.conv2 = nn.Conv2d(5, 25, kernel_size=3, padding=1)\n",
    "\n",
    "        self.maxpool = nn.MaxPool2d(kernel_size=(2, 2))\n",
    "\n",
    "        self.flatten = nn.Flatten()\n",
    "\n",
    "        self.kan1 = KANLinear(\n",
    "            in_features=6400,\n",
    "            out_features=256,\n",
    "            grid_size=10,\n",
    "            spline_order=3,\n",
    "            scale_noise=0.01,\n",
    "            scale_base=1,\n",
    "            scale_spline=1,\n",
    "            base_activation=nn.SiLU,\n",
    "            grid_eps=0.02,\n",
    "            grid_range=[0, 1]\n",
    "        )\n",
    "\n",
    "        self.kan2 = KANLinear(\n",
    "            in_features=256,\n",
    "            out_features=9, # out_features will change as per the number of output class of the dataset being considered. \n",
    "            grid_size=10,\n",
    "            spline_order=3,\n",
    "            scale_noise=0.01,\n",
    "            scale_base=1,\n",
    "            scale_spline=1,\n",
    "            base_activation=nn.SiLU,\n",
    "            grid_eps=0.02,\n",
    "            grid_range=[0, 1]\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.conv1(x)\n",
    "        x = self.maxpool(x)\n",
    "        \n",
    "        x = self.conv2(x)\n",
    "        x = self.maxpool(x)\n",
    "        \n",
    "        x = self.flatten(x)\n",
    "\n",
    "        x = self.kan1(x)\n",
    "\n",
    "        x = self.kan2(x)\n",
    "        \n",
    "        x = F.log_softmax(x, dim=1)\n",
    "\n",
    "        return x\n",
    "    \n",
    "model = SuperConvolutionalKAN()\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "start_time = time.time()\n",
    "\n",
    "for epoch in range(10): \n",
    "    epoch_start_time = time.time()\n",
    "    model.train()\n",
    "    running_loss = 0.0\n",
    "    for images, labels in train_loader:\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(images)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        running_loss += loss.item()\n",
    "\n",
    "    epoch_time = time.time() - epoch_start_time\n",
    "    print(f'Epoch [{epoch + 1}/10], Loss: {running_loss / len(train_loader):.4f}, Time elapsed: {epoch_time:.2f} seconds')\n",
    "\n",
    "total_time = time.time() - start_time\n",
    "print(f\"Training completed in: {total_time:.2f} seconds\")\n",
    "\n",
    "model.eval()\n",
    "all_preds = []\n",
    "all_labels = []\n",
    "with torch.no_grad():\n",
    "    for images, labels in test_loader:\n",
    "        outputs = model(images)\n",
    "        _, preds = torch.max(outputs, 1)\n",
    "        all_preds.extend(preds.numpy())\n",
    "        all_labels.extend(labels.numpy())\n",
    "\n",
    "all_preds = np.array(all_preds)\n",
    "all_labels = np.array(all_labels)\n",
    "\n",
    "accuracy = accuracy_score(all_labels, all_preds)\n",
    "precision = precision_score(all_labels, all_preds, average='macro')\n",
    "recall = recall_score(all_labels, all_preds, average='macro')\n",
    "f1 = f1_score(all_labels, all_preds, average='macro')\n",
    "\n",
    "print(f'Accuracy: {accuracy:.4f}, Precision: {precision:.4f}, Recall: {recall:.4f}, F1 Score: {f1:.4f}')\n",
    "torch.save(model.state_dict(), 'super_kan_c_64x64.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/10], Loss: 0.5336, Time elapsed: 89.02 seconds\n",
      "Epoch [2/10], Loss: 0.0786, Time elapsed: 93.35 seconds\n",
      "Epoch [3/10], Loss: 0.0303, Time elapsed: 95.18 seconds\n",
      "Epoch [4/10], Loss: 0.0126, Time elapsed: 88.82 seconds\n",
      "Epoch [5/10], Loss: 0.0069, Time elapsed: 90.64 seconds\n",
      "Epoch [6/10], Loss: 0.0038, Time elapsed: 93.18 seconds\n",
      "Epoch [7/10], Loss: 0.0021, Time elapsed: 95.00 seconds\n",
      "Epoch [8/10], Loss: 0.0015, Time elapsed: 99.58 seconds\n",
      "Epoch [9/10], Loss: 0.0011, Time elapsed: 99.93 seconds\n",
      "Epoch [10/10], Loss: 0.0008, Time elapsed: 103.38 seconds\n",
      "Training completed in: 948.08 seconds\n",
      "Accuracy: 0.9956, Precision: 0.9962, Recall: 0.9961, F1 Score: 0.9962\n"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, confusion_matrix, ConfusionMatrixDisplay\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import torchvision.transforms as transforms\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from PIL import Image\n",
    "import os\n",
    "import math\n",
    "import seaborn as sns\n",
    "import time\n",
    "\n",
    "\n",
    "from kan_convolutional.KANLinear import KANLinear\n",
    "from kan_convolutional.KANConv import KAN_Convolutional_Layer\n",
    "from kan_convolutional import convolution \n",
    "\n",
    "\n",
    "import os\n",
    "from PIL import Image\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torchvision.transforms as transforms\n",
    "\n",
    "class Data_Class(Dataset):\n",
    "    def __init__(self, root_dirs, transform=None):\n",
    "        self.transform = transform\n",
    "        self.image_files = []\n",
    "        self.labels = []\n",
    "        self.class_names = []\n",
    "\n",
    "        for root_dir in root_dirs:\n",
    "            for label, subfolder in enumerate(os.listdir(root_dir)):\n",
    "                subfolder_path = os.path.join(root_dir, subfolder)\n",
    "                if os.path.isdir(subfolder_path):\n",
    "                    if subfolder not in self.class_names:\n",
    "                        self.class_names.append(subfolder)\n",
    "                    label = self.class_names.index(subfolder)\n",
    "                    for img_file in os.listdir(subfolder_path):\n",
    "                        if img_file.endswith('.png'):\n",
    "                            self.image_files.append(os.path.join(subfolder_path, img_file))\n",
    "                            self.labels.append(label)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.image_files)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        img_name = self.image_files[idx]\n",
    "        image = Image.open(img_name).convert('L')\n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "        label = self.labels[idx]\n",
    "        return image, label\n",
    "\n",
    "    def get_class_names(self):\n",
    "        return self.class_names\n",
    "\n",
    "root_dirs = [\n",
    "    \"aug\"\n",
    "]\n",
    "\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize((64, 64)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.5,), (0.5,))\n",
    "])\n",
    "\n",
    "dataset = Data_Class(root_dirs=root_dirs, transform=transform)\n",
    "train_size = int(0.8 * len(dataset))\n",
    "test_size = len(dataset) - train_size\n",
    "train_dataset, test_dataset = torch.utils.data.random_split(dataset, [train_size, test_size])\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=64, shuffle=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=64, shuffle=False)\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "class NormalizedConvolutionalKAN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(NormalizedConvolutionalKAN, self).__init__()\n",
    "        \n",
    "        self.conv1 = nn.Conv2d(1, 5, kernel_size=3, padding=1)\n",
    "        self.bn1 = nn.BatchNorm2d(5)\n",
    "        \n",
    "        self.conv2 = nn.Conv2d(5, 25, kernel_size=3, padding=1)\n",
    "        self.bn2 = nn.BatchNorm2d(25)\n",
    "\n",
    "        self.maxpool = nn.MaxPool2d(kernel_size=(2, 2))\n",
    "\n",
    "        self.flatten = nn.Flatten()\n",
    "\n",
    "        self.kan1 = KANLinear(\n",
    "            in_features=25 * 16 * 16,\n",
    "            out_features=9, # out_features will change as per the number of output class of the dataset being considered. \n",
    "            grid_size=10,\n",
    "            spline_order=3,\n",
    "            scale_noise=0.01,\n",
    "            scale_base=1,\n",
    "            scale_spline=1,\n",
    "            base_activation=nn.SiLU,\n",
    "            grid_eps=0.02,\n",
    "            grid_range=[0, 1]\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = F.relu(self.bn1(self.conv1(x)))\n",
    "        x = self.maxpool(x)\n",
    "        \n",
    "        x = F.relu(self.bn2(self.conv2(x)))\n",
    "        x = self.maxpool(x)\n",
    "        \n",
    "        x = self.flatten(x)\n",
    "        x = self.kan1(x)\n",
    "        \n",
    "        x = F.log_softmax(x, dim=1)  \n",
    "\n",
    "        return x\n",
    "    \n",
    "model = NormalizedConvolutionalKAN()\n",
    "\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "start_time = time.time()\n",
    "\n",
    "for epoch in range(10): \n",
    "    epoch_start_time = time.time()\n",
    "    model.train()\n",
    "    running_loss = 0.0\n",
    "    for images, labels in train_loader:\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(images)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        running_loss += loss.item()\n",
    "\n",
    "    epoch_time = time.time() - epoch_start_time\n",
    "    print(f'Epoch [{epoch + 1}/10], Loss: {running_loss / len(train_loader):.4f}, Time elapsed: {epoch_time:.2f} seconds')\n",
    "\n",
    "total_time = time.time() - start_time\n",
    "print(f\"Training completed in: {total_time:.2f} seconds\")\n",
    "\n",
    "\n",
    "model.eval()\n",
    "all_preds = []\n",
    "all_labels = []\n",
    "with torch.no_grad():\n",
    "    for images, labels in test_loader:\n",
    "        outputs = model(images)\n",
    "        _, preds = torch.max(outputs, 1)\n",
    "        all_preds.extend(preds.numpy())\n",
    "        all_labels.extend(labels.numpy())\n",
    "\n",
    "all_preds = np.array(all_preds)\n",
    "all_labels = np.array(all_labels)\n",
    "\n",
    "accuracy = accuracy_score(all_labels, all_preds)\n",
    "precision = precision_score(all_labels, all_preds, average='macro')\n",
    "recall = recall_score(all_labels, all_preds, average='macro')\n",
    "f1 = f1_score(all_labels, all_preds, average='macro')\n",
    "\n",
    "print(f'Accuracy: {accuracy:.4f}, Precision: {precision:.4f}, Recall: {recall:.4f}, F1 Score: {f1:.4f}')\n",
    "torch.save(model.state_dict(), 'kan_c_bn_64x64.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/10], Loss: 1.1543, Time elapsed: 107.98 seconds\n",
      "Epoch [2/10], Loss: 0.5174, Time elapsed: 105.14 seconds\n",
      "Epoch [3/10], Loss: 0.2592, Time elapsed: 109.31 seconds\n",
      "Epoch [4/10], Loss: 0.1367, Time elapsed: 118.58 seconds\n",
      "Epoch [5/10], Loss: 0.0867, Time elapsed: 121.83 seconds\n",
      "Epoch [6/10], Loss: 0.0615, Time elapsed: 126.64 seconds\n",
      "Epoch [7/10], Loss: 0.0482, Time elapsed: 121.67 seconds\n",
      "Epoch [8/10], Loss: 0.0379, Time elapsed: 121.63 seconds\n",
      "Epoch [9/10], Loss: 0.0297, Time elapsed: 122.16 seconds\n",
      "Epoch [10/10], Loss: 0.0226, Time elapsed: 118.72 seconds\n",
      "Training completed in: 1173.66 seconds\n",
      "Accuracy: 0.9932, Precision: 0.9938, Recall: 0.9939, F1 Score: 0.9939\n"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, confusion_matrix, ConfusionMatrixDisplay\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import torchvision.transforms as transforms\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from PIL import Image\n",
    "import os\n",
    "import math\n",
    "import seaborn as sns\n",
    "import time\n",
    "\n",
    "\n",
    "from kan_convolutional.KANLinear import KANLinear\n",
    "from kan_convolutional.KANConv import KAN_Convolutional_Layer\n",
    "from kan_convolutional import convolution \n",
    "\n",
    "\n",
    "\n",
    "import os\n",
    "from PIL import Image\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torchvision.transforms as transforms\n",
    "\n",
    "class Data_Class(Dataset):\n",
    "    def __init__(self, root_dirs, transform=None):\n",
    "        self.transform = transform\n",
    "        self.image_files = []\n",
    "        self.labels = []\n",
    "        self.class_names = []\n",
    "\n",
    "        for root_dir in root_dirs:\n",
    "            for label, subfolder in enumerate(os.listdir(root_dir)):\n",
    "                subfolder_path = os.path.join(root_dir, subfolder)\n",
    "                if os.path.isdir(subfolder_path):\n",
    "                    if subfolder not in self.class_names:\n",
    "                        self.class_names.append(subfolder)\n",
    "                    label = self.class_names.index(subfolder)\n",
    "                    for img_file in os.listdir(subfolder_path):\n",
    "                        if img_file.endswith('.png'):\n",
    "                            self.image_files.append(os.path.join(subfolder_path, img_file))\n",
    "                            self.labels.append(label)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.image_files)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        img_name = self.image_files[idx]\n",
    "        image = Image.open(img_name).convert('L')\n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "        label = self.labels[idx]\n",
    "        return image, label\n",
    "\n",
    "    def get_class_names(self):\n",
    "        return self.class_names\n",
    "\n",
    "root_dirs = [\n",
    "    \"aug\"\n",
    "]\n",
    "\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize((64, 64)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.5,), (0.5,))\n",
    "])\n",
    "\n",
    "dataset = Data_Class(root_dirs=root_dirs, transform=transform)\n",
    "train_size = int(0.8 * len(dataset))\n",
    "test_size = len(dataset) - train_size\n",
    "train_dataset, test_dataset = torch.utils.data.random_split(dataset, [train_size, test_size])\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=64, shuffle=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=64, shuffle=False)\n",
    "\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "class ConvolutionalKAN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(ConvolutionalKAN, self).__init__()\n",
    "        \n",
    "        self.conv1 = nn.Conv2d(1, 5, kernel_size=3, padding=1)\n",
    "        \n",
    "        self.conv2 = nn.Conv2d(5, 25, kernel_size=3, padding=1)\n",
    "\n",
    "        self.maxpool = nn.MaxPool2d(kernel_size=(2, 2))\n",
    "\n",
    "        self.flatten = nn.Flatten()\n",
    "\n",
    "        self.kan1 = KANLinear(\n",
    "            in_features=25 * 16 * 16,\n",
    "            out_features=9, # out_features will change as per the number of output class of the dataset being considered. \n",
    "            grid_size=10,\n",
    "            spline_order=3,\n",
    "            scale_noise=0.01,\n",
    "            scale_base=1,\n",
    "            scale_spline=1,\n",
    "            base_activation=nn.SiLU,\n",
    "            grid_eps=0.02,\n",
    "            grid_range=[0, 1]\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.conv1(x)\n",
    "        x = self.maxpool(x)\n",
    "        \n",
    "        x = self.conv2(x)\n",
    "        x = self.maxpool(x)\n",
    "        \n",
    "        x = self.flatten(x)\n",
    "        x = self.kan1(x)\n",
    "        \n",
    "        x = F.log_softmax(x, dim=1)  \n",
    "\n",
    "        return x\n",
    "    \n",
    "model = ConvolutionalKAN()\n",
    "\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "start_time = time.time()\n",
    "\n",
    "for epoch in range(10): \n",
    "    epoch_start_time = time.time()\n",
    "    model.train()\n",
    "    running_loss = 0.0\n",
    "    for images, labels in train_loader:\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(images)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        running_loss += loss.item()\n",
    "\n",
    "    epoch_time = time.time() - epoch_start_time\n",
    "    print(f'Epoch [{epoch + 1}/10], Loss: {running_loss / len(train_loader):.4f}, Time elapsed: {epoch_time:.2f} seconds')\n",
    "\n",
    "total_time = time.time() - start_time\n",
    "print(f\"Training completed in: {total_time:.2f} seconds\")\n",
    "\n",
    "\n",
    "model.eval()\n",
    "all_preds = []\n",
    "all_labels = []\n",
    "with torch.no_grad():\n",
    "    for images, labels in test_loader:\n",
    "        outputs = model(images)\n",
    "        _, preds = torch.max(outputs, 1)\n",
    "        all_preds.extend(preds.numpy())\n",
    "        all_labels.extend(labels.numpy())\n",
    "\n",
    "all_preds = np.array(all_preds)\n",
    "all_labels = np.array(all_labels)\n",
    "\n",
    "accuracy = accuracy_score(all_labels, all_preds)\n",
    "precision = precision_score(all_labels, all_preds, average='macro')\n",
    "recall = recall_score(all_labels, all_preds, average='macro')\n",
    "f1 = f1_score(all_labels, all_preds, average='macro')\n",
    "\n",
    "print(f'Accuracy: {accuracy:.4f}, Precision: {precision:.4f}, Recall: {recall:.4f}, F1 Score: {f1:.4f}')\n",
    "torch.save(model.state_dict(), 'kan_c_64x64.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/10], Loss: 1.1672, Time elapsed: 69.14 seconds\n",
      "Epoch [2/10], Loss: 0.4149, Time elapsed: 60.87 seconds\n",
      "Epoch [3/10], Loss: 0.2031, Time elapsed: 56.43 seconds\n",
      "Epoch [4/10], Loss: 0.1262, Time elapsed: 55.37 seconds\n",
      "Epoch [5/10], Loss: 0.0946, Time elapsed: 52.98 seconds\n",
      "Epoch [6/10], Loss: 0.0740, Time elapsed: 60.39 seconds\n",
      "Epoch [7/10], Loss: 0.0629, Time elapsed: 63.96 seconds\n",
      "Epoch [8/10], Loss: 0.0476, Time elapsed: 64.93 seconds\n",
      "Epoch [9/10], Loss: 0.0379, Time elapsed: 65.65 seconds\n",
      "Epoch [10/10], Loss: 0.0324, Time elapsed: 70.40 seconds\n",
      "Training completed in: 620.13 seconds\n",
      "Accuracy: 0.9883, Precision: 0.9905, Recall: 0.9886, F1 Score: 0.9893\n"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, confusion_matrix, ConfusionMatrixDisplay\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import torchvision.transforms as transforms\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from PIL import Image\n",
    "import os\n",
    "import math\n",
    "import seaborn as sns\n",
    "import time\n",
    "\n",
    "\n",
    "from kan_convolutional.KANLinear import KANLinear\n",
    "from kan_convolutional.KANConv import KAN_Convolutional_Layer\n",
    "from kan_convolutional import convolution \n",
    "\n",
    "import os\n",
    "from PIL import Image\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torchvision.transforms as transforms\n",
    "\n",
    "class Data_Class(Dataset):\n",
    "    def __init__(self, root_dirs, transform=None):\n",
    "        self.transform = transform\n",
    "        self.image_files = []\n",
    "        self.labels = []\n",
    "        self.class_names = []\n",
    "\n",
    "        for root_dir in root_dirs:\n",
    "            for label, subfolder in enumerate(os.listdir(root_dir)):\n",
    "                subfolder_path = os.path.join(root_dir, subfolder)\n",
    "                if os.path.isdir(subfolder_path):\n",
    "                    if subfolder not in self.class_names:\n",
    "                        self.class_names.append(subfolder)\n",
    "                    label = self.class_names.index(subfolder)\n",
    "                    for img_file in os.listdir(subfolder_path):\n",
    "                        if img_file.endswith('.png'):\n",
    "                            self.image_files.append(os.path.join(subfolder_path, img_file))\n",
    "                            self.labels.append(label)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.image_files)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        img_name = self.image_files[idx]\n",
    "        image = Image.open(img_name).convert('L')\n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "        label = self.labels[idx]\n",
    "        return image, label\n",
    "\n",
    "    def get_class_names(self):\n",
    "        return self.class_names\n",
    "\n",
    "root_dirs = [\n",
    "    \"aug\"\n",
    "]\n",
    "\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize((64, 64)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.5,), (0.5,))\n",
    "])\n",
    "\n",
    "dataset = Data_Class(root_dirs=root_dirs, transform=transform)\n",
    "train_size = int(0.8 * len(dataset))\n",
    "test_size = len(dataset) - train_size\n",
    "train_dataset, test_dataset = torch.utils.data.random_split(dataset, [train_size, test_size])\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=64, shuffle=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=64, shuffle=False)\n",
    "\n",
    "\n",
    "class SimpleLinear(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(SimpleLinear, self).__init__()\n",
    "        self.kan = KANLinear(\n",
    "            in_features=64 * 64,\n",
    "            out_features=9, # out_features will change as per the number of output class of the dataset being considered. \n",
    "            grid_size=10,\n",
    "            spline_order=3,\n",
    "            scale_noise=0.01,\n",
    "            scale_base=1,\n",
    "            scale_spline=1,\n",
    "            base_activation=nn.SiLU,\n",
    "            grid_eps=0.02,\n",
    "            grid_range=[0, 1]\n",
    "        )\n",
    "        self.flatten = nn.Flatten()\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.flatten(x)\n",
    "        x = self.kan(x)\n",
    "        x = F.log_softmax(x, dim=1)\n",
    "        return x\n",
    "\n",
    "model = SimpleLinear()\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "start_time = time.time()\n",
    "\n",
    "for epoch in range(10): \n",
    "    epoch_start_time = time.time()\n",
    "    model.train()\n",
    "    running_loss = 0.0\n",
    "    for images, labels in train_loader:\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(images)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        running_loss += loss.item()\n",
    "\n",
    "    epoch_time = time.time() - epoch_start_time\n",
    "    print(f'Epoch [{epoch + 1}/10], Loss: {running_loss / len(train_loader):.4f}, Time elapsed: {epoch_time:.2f} seconds')\n",
    "\n",
    "total_time = time.time() - start_time\n",
    "print(f\"Training completed in: {total_time:.2f} seconds\")\n",
    "\n",
    "\n",
    "model.eval()\n",
    "all_preds = []\n",
    "all_labels = []\n",
    "with torch.no_grad():\n",
    "    for images, labels in test_loader:\n",
    "        outputs = model(images)\n",
    "        _, preds = torch.max(outputs, 1)\n",
    "        all_preds.extend(preds.numpy())\n",
    "        all_labels.extend(labels.numpy())\n",
    "\n",
    "all_preds = np.array(all_preds)\n",
    "all_labels = np.array(all_labels)\n",
    "\n",
    "accuracy = accuracy_score(all_labels, all_preds)\n",
    "precision = precision_score(all_labels, all_preds, average='macro')\n",
    "recall = recall_score(all_labels, all_preds, average='macro')\n",
    "f1 = f1_score(all_labels, all_preds, average='macro')\n",
    "\n",
    "print(f'Accuracy: {accuracy:.4f}, Precision: {precision:.4f}, Recall: {recall:.4f}, F1 Score: {f1:.4f}')\n",
    "torch.save(model.state_dict(), 'kan_l_64x64.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/10], Loss: 1.8736, Time elapsed: 109.29 seconds\n",
      "Epoch [2/10], Loss: 0.9522, Time elapsed: 112.31 seconds\n",
      "Epoch [3/10], Loss: 0.7994, Time elapsed: 121.61 seconds\n",
      "Epoch [4/10], Loss: 0.7362, Time elapsed: 162.00 seconds\n",
      "Epoch [5/10], Loss: 0.7099, Time elapsed: 175.27 seconds\n",
      "Epoch [6/10], Loss: 0.5770, Time elapsed: 157.71 seconds\n",
      "Epoch [7/10], Loss: 0.4247, Time elapsed: 159.87 seconds\n",
      "Epoch [8/10], Loss: 0.2759, Time elapsed: 172.21 seconds\n",
      "Epoch [9/10], Loss: 0.2825, Time elapsed: 188.69 seconds\n",
      "Epoch [10/10], Loss: 0.2261, Time elapsed: 190.45 seconds\n",
      "Training completed in: 1549.42 seconds\n",
      "Accuracy: 0.9106\n",
      "Precision: 0.9186\n",
      "Recall: 0.9204\n",
      "F1 Score: 0.9192\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "     Class 0       0.71      0.68      0.70       245\n",
      "     Class 1       0.71      0.71      0.71       270\n",
      "     Class 2       0.94      0.91      0.93       265\n",
      "     Class 3       0.91      0.99      0.95       227\n",
      "     Class 4       1.00      0.99      1.00       230\n",
      "     Class 5       0.99      1.00      1.00       211\n",
      "     Class 6       1.00      0.99      1.00       193\n",
      "     Class 7       1.00      1.00      1.00       206\n",
      "     Class 8       1.00      1.00      1.00       211\n",
      "\n",
      "    accuracy                           0.91      2058\n",
      "   macro avg       0.92      0.92      0.92      2058\n",
      "weighted avg       0.91      0.91      0.91      2058\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import DataLoader, Dataset, random_split\n",
    "from torchvision import transforms\n",
    "from torch.optim import Adam\n",
    "import os\n",
    "import time\n",
    "from PIL import Image\n",
    "from sklearn.metrics import accuracy_score, precision_recall_fscore_support, classification_report\n",
    "import numpy as np\n",
    "\n",
    "# Dataset class\n",
    "class Data_Class(Dataset):\n",
    "    def __init__(self, root_dirs, transform=None):\n",
    "        self.root_dirs = root_dirs\n",
    "        self.transform = transform\n",
    "        self.image_paths = []\n",
    "        self.labels = []\n",
    "        self.classes = sorted(os.listdir(root_dirs[0]))\n",
    "        \n",
    "        for root_dir in root_dirs:\n",
    "            for label, class_name in enumerate(self.classes):\n",
    "                class_dir = os.path.join(root_dir, class_name)\n",
    "                for img_name in os.listdir(class_dir):\n",
    "                    img_path = os.path.join(class_dir, img_name)\n",
    "                    self.image_paths.append(img_path)\n",
    "                    self.labels.append(label)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.image_paths)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        img_path = self.image_paths[idx]\n",
    "        image = Image.open(img_path).convert(\"L\")\n",
    "        label = self.labels[idx]\n",
    "\n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "\n",
    "        return image, label\n",
    "\n",
    "class Inception(nn.Module):\n",
    "    def __init__(self, in_channels, out_1x1, out_3x3_reduce, out_3x3, out_5x5_reduce, out_5x5, out_pool_proj):\n",
    "        super(Inception, self).__init__()\n",
    "        \n",
    "        self.branch1 = nn.Conv2d(in_channels, out_1x1, kernel_size=1)\n",
    "\n",
    "        self.branch2 = nn.Sequential(\n",
    "            nn.Conv2d(in_channels, out_3x3_reduce, kernel_size=1),\n",
    "            nn.Conv2d(out_3x3_reduce, out_3x3, kernel_size=3, padding=1)\n",
    "        )\n",
    "        \n",
    "        self.branch3 = nn.Sequential(\n",
    "            nn.Conv2d(in_channels, out_5x5_reduce, kernel_size=1),\n",
    "            nn.Conv2d(out_5x5_reduce, out_5x5, kernel_size=5, padding=2)\n",
    "        )\n",
    "        \n",
    "        self.branch4 = nn.Sequential(\n",
    "            nn.MaxPool2d(kernel_size=3, stride=1, padding=1),\n",
    "            nn.Conv2d(in_channels, out_pool_proj, kernel_size=1)\n",
    "        )\n",
    "    \n",
    "    def forward(self, x):\n",
    "        branch1 = self.branch1(x)\n",
    "        branch2 = self.branch2(x)\n",
    "        branch3 = self.branch3(x)\n",
    "        branch4 = self.branch4(x)\n",
    "        \n",
    "        outputs = [branch1, branch2, branch3, branch4]\n",
    "        return torch.cat(outputs, 1)\n",
    "\n",
    "class GoogleNetClassifier(nn.Module):\n",
    "    def __init__(self, num_classes):\n",
    "        super(GoogleNetClassifier, self).__init__()\n",
    "        \n",
    "        self.conv1 = nn.Conv2d(1, 64, kernel_size=7, stride=2, padding=3)\n",
    "        self.maxpool1 = nn.MaxPool2d(kernel_size=3, stride=2, padding=1)\n",
    "        \n",
    "        self.conv2 = nn.Conv2d(64, 192, kernel_size=3, stride=1, padding=1)\n",
    "        self.maxpool2 = nn.MaxPool2d(kernel_size=3, stride=2, padding=1)\n",
    "        \n",
    "        self.inception3a = Inception(192, 64, 96, 128, 16, 32, 32)\n",
    "        self.inception3b = Inception(256, 128, 128, 192, 32, 96, 64)\n",
    "        self.maxpool3 = nn.MaxPool2d(kernel_size=3, stride=2, padding=1)\n",
    "        \n",
    "        self.inception4a = Inception(480, 192, 96, 208, 16, 48, 64)\n",
    "        self.inception4b = Inception(512, 160, 112, 224, 24, 64, 64)\n",
    "        self.inception4c = Inception(512, 128, 128, 256, 24, 64, 64)\n",
    "        self.inception4d = Inception(512, 112, 144, 288, 32, 64, 64)\n",
    "        self.inception4e = Inception(528, 256, 160, 320, 32, 128, 128)\n",
    "        self.maxpool4 = nn.MaxPool2d(kernel_size=3, stride=2, padding=1)\n",
    "        \n",
    "        self.inception5a = Inception(832, 256, 160, 320, 32, 128, 128)\n",
    "        self.inception5b = Inception(832, 384, 192, 384, 48, 128, 128)\n",
    "        \n",
    "        self.avgpool = nn.AdaptiveAvgPool2d((1, 1))\n",
    "        self.dropout = nn.Dropout(0.4)\n",
    "        self.fc = nn.Linear(1024, num_classes)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = self.conv1(x)\n",
    "        x = self.maxpool1(x)\n",
    "        \n",
    "        x = self.conv2(x)\n",
    "        x = self.maxpool2(x)\n",
    "        \n",
    "        x = self.inception3a(x)\n",
    "        x = self.inception3b(x)\n",
    "        x = self.maxpool3(x)\n",
    "        \n",
    "        x = self.inception4a(x)\n",
    "        x = self.inception4b(x)\n",
    "        x = self.inception4c(x)\n",
    "        x = self.inception4d(x)\n",
    "        x = self.inception4e(x)\n",
    "        x = self.maxpool4(x)\n",
    "        \n",
    "        x = self.inception5a(x)\n",
    "        x = self.inception5b(x)\n",
    "        \n",
    "        x = self.avgpool(x)\n",
    "        x = torch.flatten(x, 1)\n",
    "        x = self.dropout(x)\n",
    "        x = self.fc(x)\n",
    "        \n",
    "        return x\n",
    "\n",
    "image_size = 64\n",
    "num_classes = 9 # num_classes will change as per the number of output class of the dataset being considered. \n",
    "\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize((image_size, image_size)),\n",
    "    transforms.ToTensor()\n",
    "])\n",
    "\n",
    "root_dirs = ['aug']\n",
    "dataset = Data_Class(root_dirs=root_dirs, transform=transform)\n",
    "train_size = int(0.8 * len(dataset))\n",
    "test_size = len(dataset) - train_size\n",
    "train_dataset, test_dataset = random_split(dataset, [train_size, test_size])\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=32, shuffle=False)\n",
    "\n",
    "model = GoogleNetClassifier(num_classes=num_classes)\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "model = model.to(device)\n",
    "\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = Adam(model.parameters(), lr=1e-4)\n",
    "\n",
    "start_time = time.time()\n",
    "num_epochs = 10\n",
    "for epoch in range(num_epochs):\n",
    "    epoch_start_time = time.time()\n",
    "    model.train()\n",
    "    running_loss = 0.0\n",
    "    for images, labels in train_loader:\n",
    "        images = images.to(device)\n",
    "        labels = labels.to(device)\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(images)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        running_loss += loss.item()\n",
    "\n",
    "    epoch_loss = running_loss / len(train_loader)\n",
    "    epoch_time = time.time() - epoch_start_time\n",
    "    print(f\"Epoch [{epoch + 1}/{num_epochs}], Loss: {epoch_loss:.4f}, Time elapsed: {epoch_time:.2f} seconds\")\n",
    "\n",
    "\n",
    "total_time = time.time() - start_time\n",
    "print(f\"Training completed in: {total_time:.2f} seconds\")\n",
    "\n",
    "\n",
    "model.eval()\n",
    "\n",
    "all_labels = []\n",
    "all_predictions = []\n",
    "\n",
    "with torch.no_grad():\n",
    "    for images, labels in test_loader:\n",
    "        images = images.to(device)\n",
    "        labels = labels.to(device)\n",
    "        \n",
    "        outputs = model(images)\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        all_labels.extend(labels.cpu().numpy())\n",
    "        all_predictions.extend(predicted.cpu().numpy())\n",
    "\n",
    "all_labels = np.array(all_labels)\n",
    "all_predictions = np.array(all_predictions)\n",
    "\n",
    "accuracy = accuracy_score(all_labels, all_predictions)\n",
    "precision, recall, f1, _ = precision_recall_fscore_support(all_labels, all_predictions, average='macro')\n",
    "\n",
    "print(f'Accuracy: {accuracy:.4f}')\n",
    "print(f'Precision: {precision:.4f}')\n",
    "print(f'Recall: {recall:.4f}')\n",
    "print(f'F1 Score: {f1:.4f}')\n",
    "\n",
    "print('\\nClassification Report:')\n",
    "print(classification_report(all_labels, all_predictions, target_names=[f'Class {i}' for i in range(num_classes)]))\n",
    "\n",
    "torch.save(model.state_dict(), 'googlenet_64x64.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/10], Loss: 2.1957, Time elapsed: 74.31 seconds\n",
      "Epoch [2/10], Loss: 1.9978, Time elapsed: 71.27 seconds\n",
      "Epoch [3/10], Loss: 1.4949, Time elapsed: 63.06 seconds\n",
      "Epoch [4/10], Loss: 1.3599, Time elapsed: 63.60 seconds\n",
      "Epoch [5/10], Loss: 1.2490, Time elapsed: 65.27 seconds\n",
      "Epoch [6/10], Loss: 1.1682, Time elapsed: 66.90 seconds\n",
      "Epoch [7/10], Loss: 1.1078, Time elapsed: 70.12 seconds\n",
      "Epoch [8/10], Loss: 1.0446, Time elapsed: 71.53 seconds\n",
      "Epoch [9/10], Loss: 0.9991, Time elapsed: 63.08 seconds\n",
      "Epoch [10/10], Loss: 0.9302, Time elapsed: 61.22 seconds\n",
      "Training completed in: 670.37 seconds\n",
      "Accuracy: 0.6302\n",
      "Precision: 0.5875\n",
      "Recall: 0.6452\n",
      "F1 Score: 0.5825\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "     Class 0       0.00      0.00      0.00       243\n",
      "     Class 1       0.27      1.00      0.43       269\n",
      "     Class 2       0.00      0.00      0.00       233\n",
      "     Class 3       0.20      0.00      0.01       245\n",
      "     Class 4       1.00      0.93      0.96       208\n",
      "     Class 5       0.95      0.94      0.95       230\n",
      "     Class 6       1.00      1.00      1.00       225\n",
      "     Class 7       0.92      1.00      0.96       217\n",
      "     Class 8       0.95      0.94      0.94       188\n",
      "\n",
      "    accuracy                           0.63      2058\n",
      "   macro avg       0.59      0.65      0.58      2058\n",
      "weighted avg       0.56      0.63      0.56      2058\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Anurag Dutta\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.9_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python39\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\Anurag Dutta\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.9_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python39\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\Anurag Dutta\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.9_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python39\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\Anurag Dutta\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.9_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python39\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import DataLoader, Dataset, random_split\n",
    "from torchvision import transforms\n",
    "from torch.optim import Adam\n",
    "import os\n",
    "import time\n",
    "from PIL import Image\n",
    "from sklearn.metrics import accuracy_score, precision_recall_fscore_support, classification_report\n",
    "import numpy as np\n",
    "\n",
    "# Dataset class\n",
    "class Data_Class(Dataset):\n",
    "    def __init__(self, root_dirs, transform=None):\n",
    "        self.root_dirs = root_dirs\n",
    "        self.transform = transform\n",
    "        self.image_paths = []\n",
    "        self.labels = []\n",
    "        self.classes = sorted(os.listdir(root_dirs[0]))\n",
    "        \n",
    "        for root_dir in root_dirs:\n",
    "            for label, class_name in enumerate(self.classes):\n",
    "                class_dir = os.path.join(root_dir, class_name)\n",
    "                for img_name in os.listdir(class_dir):\n",
    "                    img_path = os.path.join(class_dir, img_name)\n",
    "                    self.image_paths.append(img_path)\n",
    "                    self.labels.append(label)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.image_paths)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        img_path = self.image_paths[idx]\n",
    "        image = Image.open(img_path).convert(\"L\")\n",
    "        label = self.labels[idx]\n",
    "\n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "\n",
    "        return image, label\n",
    "\n",
    "class Patches(nn.Module):\n",
    "    def __init__(self, patch_size, in_channels=1):\n",
    "        super(Patches, self).__init__()\n",
    "        self.patch_size = patch_size\n",
    "        self.unfold = nn.Unfold(kernel_size=patch_size, stride=patch_size)\n",
    "\n",
    "    def forward(self, x):\n",
    "        patches = self.unfold(x)\n",
    "        patches = patches.transpose(1, 2)\n",
    "        return patches\n",
    "\n",
    "class PatchEncoder(nn.Module):\n",
    "    def __init__(self, num_patches, projection_dim):\n",
    "        super(PatchEncoder, self).__init__()\n",
    "        self.projection = nn.Linear(16*16, projection_dim)\n",
    "        self.position_embedding = nn.Parameter(torch.randn(1, num_patches, projection_dim))\n",
    "\n",
    "    def forward(self, patches):\n",
    "        encoded = self.projection(patches) + self.position_embedding\n",
    "        return encoded\n",
    "\n",
    "class MLP(nn.Module):\n",
    "    def __init__(self, hidden_units, dropout_rate):\n",
    "        super(MLP, self).__init__()\n",
    "        layers = []\n",
    "        for units in hidden_units:\n",
    "            layers.append(nn.Linear(units[0], units[1]))\n",
    "            layers.append(nn.GELU())\n",
    "            layers.append(nn.Dropout(dropout_rate))\n",
    "        self.mlp = nn.Sequential(*layers)\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.mlp(x)\n",
    "\n",
    "class VisionTransformer(nn.Module):\n",
    "    def __init__(self, image_size, patch_size, num_patches, projection_dim, num_heads, transformer_layers, transformer_units, mlp_head_units, num_classes):\n",
    "        super(VisionTransformer, self).__init__()\n",
    "        self.patches = Patches(patch_size=patch_size)\n",
    "        self.patch_encoder = PatchEncoder(num_patches=num_patches, projection_dim=projection_dim)\n",
    "        self.transformer_layers = nn.ModuleList([\n",
    "            nn.TransformerEncoderLayer(\n",
    "                d_model=projection_dim,\n",
    "                nhead=num_heads,\n",
    "                dim_feedforward=transformer_units[0][1],\n",
    "                dropout=0.1\n",
    "            )\n",
    "            for _ in range(transformer_layers)\n",
    "        ])\n",
    "        self.mlp_head = MLP(mlp_head_units, dropout_rate=0.5)\n",
    "        self.classifier = nn.Linear(mlp_head_units[-1][1], num_classes)\n",
    "\n",
    "    def forward(self, x):\n",
    "        patches = self.patches(x)\n",
    "        encoded_patches = self.patch_encoder(patches)\n",
    "\n",
    "        for transformer_layer in self.transformer_layers:\n",
    "            encoded_patches = transformer_layer(encoded_patches)\n",
    "\n",
    "        representation = encoded_patches.mean(dim=1)\n",
    "        features = self.mlp_head(representation)\n",
    "        logits = self.classifier(features)\n",
    "\n",
    "        return logits\n",
    "\n",
    "image_size = 64\n",
    "patch_size = 16\n",
    "num_patches = (image_size // patch_size) ** 2\n",
    "projection_dim = 64\n",
    "num_heads = 8\n",
    "transformer_layers = 6\n",
    "transformer_units = [(projection_dim, projection_dim * 4)]\n",
    "mlp_head_units = [(projection_dim, projection_dim * 2), (projection_dim * 2, 512)]\n",
    "num_classes = 9 # num_classes will change as per the number of output class of the dataset being considered. \n",
    "\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize((image_size, image_size)),\n",
    "    transforms.ToTensor()\n",
    "])\n",
    "\n",
    "root_dirs = ['aug']\n",
    "dataset = Data_Class(root_dirs=root_dirs, transform=transform)\n",
    "train_size = int(0.8 * len(dataset))\n",
    "test_size = len(dataset) - train_size\n",
    "train_dataset, test_dataset = random_split(dataset, [train_size, test_size])\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=32, shuffle=False)\n",
    "\n",
    "model = VisionTransformer(image_size=image_size, patch_size=patch_size, num_patches=num_patches,\n",
    "                          projection_dim=projection_dim, num_heads=num_heads, transformer_layers=transformer_layers,\n",
    "                          transformer_units=transformer_units, mlp_head_units=mlp_head_units, num_classes=num_classes)\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "model = model.to(device)\n",
    "\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = Adam(model.parameters(), lr=1e-4)\n",
    "\n",
    "start_time = time.time()\n",
    "num_epochs = 10\n",
    "for epoch in range(num_epochs):\n",
    "    epoch_start_time = time.time()\n",
    "    model.train()\n",
    "    running_loss = 0.0\n",
    "    for images, labels in train_loader:\n",
    "        images = images.to(device)\n",
    "        labels = labels.to(device)\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(images)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        running_loss += loss.item()\n",
    "\n",
    "    epoch_loss = running_loss / len(train_loader)\n",
    "    epoch_time = time.time() - epoch_start_time\n",
    "    print(f\"Epoch [{epoch + 1}/{num_epochs}], Loss: {running_loss / len(train_loader):.4f}, Time elapsed: {epoch_time:.2f} seconds\")\n",
    "\n",
    "\n",
    "total_time = time.time() - start_time\n",
    "print(f\"Training completed in: {total_time:.2f} seconds\")\n",
    "\n",
    "model.eval()\n",
    "all_labels = []\n",
    "all_predictions = []\n",
    "\n",
    "with torch.no_grad():\n",
    "    for images, labels in test_loader:\n",
    "        outputs = model(images)\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        all_labels.extend(labels.cpu().numpy())\n",
    "        all_predictions.extend(predicted.cpu().numpy())\n",
    "\n",
    "all_labels = np.array(all_labels)\n",
    "all_predictions = np.array(all_predictions)\n",
    "\n",
    "accuracy = accuracy_score(all_labels, all_predictions)\n",
    "precision, recall, f1, _ = precision_recall_fscore_support(all_labels, all_predictions, average='macro')\n",
    "\n",
    "print(f'Accuracy: {accuracy:.4f}')\n",
    "print(f'Precision: {precision:.4f}')\n",
    "print(f'Recall: {recall:.4f}')\n",
    "print(f'F1 Score: {f1:.4f}')\n",
    "\n",
    "print('\\nClassification Report:')\n",
    "print(classification_report(all_labels, all_predictions, target_names=[f'Class {i}' for i in range(num_classes)]))\n",
    "\n",
    "torch.save(model.state_dict(), 'vit_64x64.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/10], Loss: 0.3036, Time elapsed: 256.80 seconds\n",
      "Epoch [2/10], Loss: 0.0869, Time elapsed: 293.45 seconds\n",
      "Epoch [3/10], Loss: 0.0493, Time elapsed: 297.83 seconds\n",
      "Epoch [4/10], Loss: 0.0306, Time elapsed: 293.64 seconds\n",
      "Epoch [5/10], Loss: 0.0270, Time elapsed: 227.83 seconds\n",
      "Epoch [6/10], Loss: 0.0313, Time elapsed: 159.57 seconds\n",
      "Epoch [7/10], Loss: 0.0192, Time elapsed: 140.64 seconds\n",
      "Epoch [8/10], Loss: 0.0120, Time elapsed: 157.60 seconds\n",
      "Epoch [9/10], Loss: 0.0317, Time elapsed: 159.82 seconds\n",
      "Epoch [10/10], Loss: 0.0126, Time elapsed: 170.02 seconds\n",
      "Training completed in: 2157.21 seconds\n",
      "Accuracy: 0.9947\n",
      "Precision: 0.9951\n",
      "Recall: 0.9950\n",
      "F1 Score: 0.9950\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "     Class 0       0.99      0.97      0.98       239\n",
      "     Class 1       0.98      0.99      0.98       247\n",
      "     Class 2       0.99      1.00      0.99       280\n",
      "     Class 3       1.00      1.00      1.00       228\n",
      "     Class 4       1.00      1.00      1.00       224\n",
      "     Class 5       1.00      1.00      1.00       212\n",
      "     Class 6       1.00      1.00      1.00       208\n",
      "     Class 7       1.00      1.00      1.00       212\n",
      "     Class 8       1.00      1.00      1.00       208\n",
      "\n",
      "    accuracy                           0.99      2058\n",
      "   macro avg       1.00      0.99      1.00      2058\n",
      "weighted avg       0.99      0.99      0.99      2058\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import DataLoader, Dataset, random_split\n",
    "from torchvision import transforms\n",
    "from torch.optim import Adam\n",
    "import os\n",
    "import time\n",
    "from PIL import Image\n",
    "from sklearn.metrics import accuracy_score, precision_recall_fscore_support, classification_report\n",
    "import numpy as np\n",
    "\n",
    "# Dataset class\n",
    "class Data_Class(Dataset):\n",
    "    def __init__(self, root_dirs, transform=None):\n",
    "        self.root_dirs = root_dirs\n",
    "        self.transform = transform\n",
    "        self.image_paths = []\n",
    "        self.labels = []\n",
    "        self.classes = sorted(os.listdir(root_dirs[0]))\n",
    "        \n",
    "        for root_dir in root_dirs:\n",
    "            for label, class_name in enumerate(self.classes):\n",
    "                class_dir = os.path.join(root_dir, class_name)\n",
    "                for img_name in os.listdir(class_dir):\n",
    "                    img_path = os.path.join(class_dir, img_name)\n",
    "                    self.image_paths.append(img_path)\n",
    "                    self.labels.append(label)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.image_paths)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        img_path = self.image_paths[idx]\n",
    "        image = Image.open(img_path).convert(\"L\")\n",
    "        label = self.labels[idx]\n",
    "\n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "\n",
    "        return image, label\n",
    "\n",
    "class BasicBlock(nn.Module):\n",
    "    expansion = 1\n",
    "\n",
    "    def __init__(self, in_channels, out_channels, stride=1, downsample=None):\n",
    "        super(BasicBlock, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(in_channels, out_channels, kernel_size=3, stride=stride, padding=1, bias=False)\n",
    "        self.bn1 = nn.BatchNorm2d(out_channels)\n",
    "        self.relu = nn.ReLU(inplace=True)\n",
    "        self.conv2 = nn.Conv2d(out_channels, out_channels, kernel_size=3, stride=1, padding=1, bias=False)\n",
    "        self.bn2 = nn.BatchNorm2d(out_channels)\n",
    "        self.downsample = downsample\n",
    "\n",
    "    def forward(self, x):\n",
    "        identity = x\n",
    "\n",
    "        if self.downsample is not None:\n",
    "            identity = self.downsample(x)\n",
    "\n",
    "        out = self.conv1(x)\n",
    "        out = self.bn1(out)\n",
    "        out = self.relu(out)\n",
    "        out = self.conv2(out)\n",
    "        out = self.bn2(out)\n",
    "        out += identity\n",
    "        out = self.relu(out)\n",
    "\n",
    "        return out\n",
    "\n",
    "class ResNet(nn.Module):\n",
    "    def __init__(self, block, layers, num_classes=1000):\n",
    "        super(ResNet, self).__init__()\n",
    "        self.in_channels = 64\n",
    "        self.conv1 = nn.Conv2d(1, 64, kernel_size=7, stride=2, padding=3, bias=False)\n",
    "        self.bn1 = nn.BatchNorm2d(64)\n",
    "        self.relu = nn.ReLU(inplace=True)\n",
    "        self.maxpool = nn.MaxPool2d(kernel_size=3, stride=2, padding=1)\n",
    "        self.layer1 = self._make_layer(block, 64, layers[0])\n",
    "        self.layer2 = self._make_layer(block, 128, layers[1], stride=2)\n",
    "        self.layer3 = self._make_layer(block, 256, layers[2], stride=2)\n",
    "        self.layer4 = self._make_layer(block, 512, layers[3], stride=2)\n",
    "        self.avgpool = nn.AdaptiveAvgPool2d((1, 1))\n",
    "        self.fc = nn.Linear(512 * block.expansion, num_classes)\n",
    "\n",
    "    def _make_layer(self, block, out_channels, blocks, stride=1):\n",
    "        downsample = None\n",
    "        if stride != 1 or self.in_channels != out_channels * block.expansion:\n",
    "            downsample = nn.Sequential(\n",
    "                nn.Conv2d(self.in_channels, out_channels * block.expansion, kernel_size=1, stride=stride, bias=False),\n",
    "                nn.BatchNorm2d(out_channels * block.expansion),\n",
    "            )\n",
    "\n",
    "        layers = []\n",
    "        layers.append(block(self.in_channels, out_channels, stride, downsample))\n",
    "        self.in_channels = out_channels * block.expansion\n",
    "        for _ in range(1, blocks):\n",
    "            layers.append(block(self.in_channels, out_channels))\n",
    "\n",
    "        return nn.Sequential(*layers)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.conv1(x)\n",
    "        x = self.bn1(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.maxpool(x)\n",
    "\n",
    "        x = self.layer1(x)\n",
    "        x = self.layer2(x)\n",
    "        x = self.layer3(x)\n",
    "        x = self.layer4(x)\n",
    "\n",
    "        x = self.avgpool(x)\n",
    "        x = torch.flatten(x, 1)\n",
    "        x = self.fc(x)\n",
    "\n",
    "        return x\n",
    "\n",
    "def resnet18(num_classes):\n",
    "    return ResNet(BasicBlock, [2, 2, 2, 2], num_classes=num_classes)\n",
    "\n",
    "image_size = 64\n",
    "num_classes = 9 # num_classes will change as per the number of output class of the dataset being considered. \n",
    "\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize((image_size, image_size)),\n",
    "    transforms.ToTensor()\n",
    "])\n",
    "\n",
    "root_dirs = ['aug']\n",
    "dataset = Data_Class(root_dirs=root_dirs, transform=transform)\n",
    "train_size = int(0.8 * len(dataset))\n",
    "test_size = len(dataset) - train_size\n",
    "train_dataset, test_dataset = random_split(dataset, [train_size, test_size])\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=32, shuffle=False)\n",
    "\n",
    "model = resnet18(num_classes=num_classes)\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "model = model.to(device)\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = Adam(model.parameters(), lr=1e-4)\n",
    "\n",
    "start_time = time.time()\n",
    "num_epochs = 10\n",
    "for epoch in range(num_epochs):\n",
    "    epoch_start_time = time.time()\n",
    "    model.train()\n",
    "    running_loss = 0.0\n",
    "    for images, labels in train_loader:\n",
    "        images = images.to(device)\n",
    "        labels = labels.to(device)\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(images)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        running_loss += loss.item()\n",
    "\n",
    "    epoch_loss = running_loss / len(train_loader)\n",
    "    epoch_time = time.time() - epoch_start_time\n",
    "    print(f\"Epoch [{epoch + 1}/{num_epochs}], Loss: {epoch_loss:.4f}, Time elapsed: {epoch_time:.2f} seconds\")\n",
    "\n",
    "\n",
    "total_time = time.time() - start_time\n",
    "print(f\"Training completed in: {total_time:.2f} seconds\")\n",
    "\n",
    "model.eval()\n",
    "all_labels = []\n",
    "all_predictions = []\n",
    "\n",
    "with torch.no_grad():\n",
    "    for images, labels in test_loader:\n",
    "        images = images.to(device)\n",
    "        labels = labels.to(device)\n",
    "        \n",
    "        outputs = model(images)\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        all_labels.extend(labels.cpu().numpy())\n",
    "        all_predictions.extend(predicted.cpu().numpy())\n",
    "\n",
    "all_labels = np.array(all_labels)\n",
    "all_predictions = np.array(all_predictions)\n",
    "\n",
    "accuracy = accuracy_score(all_labels, all_predictions)\n",
    "precision, recall, f1, _ = precision_recall_fscore_support(all_labels, all_predictions, average='macro')\n",
    "\n",
    "print(f'Accuracy: {accuracy:.4f}')\n",
    "print(f'Precision: {precision:.4f}')\n",
    "print(f'Recall: {recall:.4f}')\n",
    "print(f'F1 Score: {f1:.4f}')\n",
    "\n",
    "print('\\nClassification Report:')\n",
    "print(classification_report(all_labels, all_predictions, target_names=[f'Class {i}' for i in range(num_classes)]))\n",
    "\n",
    "torch.save(model.state_dict(), 'resnet_64x64.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/10], Loss: 2.1876, Time elapsed: 96.87 seconds\n",
      "Epoch [2/10], Loss: 1.8415, Time elapsed: 70.81 seconds\n",
      "Epoch [3/10], Loss: 1.5181, Time elapsed: 59.30 seconds\n",
      "Epoch [4/10], Loss: 1.3740, Time elapsed: 63.37 seconds\n",
      "Epoch [5/10], Loss: 1.2127, Time elapsed: 60.30 seconds\n",
      "Epoch [6/10], Loss: 1.0720, Time elapsed: 70.48 seconds\n",
      "Epoch [7/10], Loss: 0.9735, Time elapsed: 64.88 seconds\n",
      "Epoch [8/10], Loss: 0.9131, Time elapsed: 64.51 seconds\n",
      "Epoch [9/10], Loss: 0.8736, Time elapsed: 67.73 seconds\n",
      "Epoch [10/10], Loss: 0.8400, Time elapsed: 58.53 seconds\n",
      "Training completed in: 676.78 seconds\n",
      "Accuracy: 0.6283\n",
      "Precision: 0.6144\n",
      "Recall: 0.6611\n",
      "F1 Score: 0.5950\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "     Class 0       0.00      0.00      0.00       229\n",
      "     Class 1       0.00      0.00      0.00       277\n",
      "     Class 2       0.25      1.00      0.40       250\n",
      "     Class 3       0.33      0.00      0.01       248\n",
      "     Class 4       1.00      0.97      0.98       232\n",
      "     Class 5       0.98      1.00      0.99       211\n",
      "     Class 6       1.00      1.00      1.00       220\n",
      "     Class 7       1.00      1.00      1.00       187\n",
      "     Class 8       0.97      0.98      0.97       204\n",
      "\n",
      "    accuracy                           0.63      2058\n",
      "   macro avg       0.61      0.66      0.59      2058\n",
      "weighted avg       0.58      0.63      0.56      2058\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Anurag Dutta\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.9_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python39\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\Anurag Dutta\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.9_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python39\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\Anurag Dutta\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.9_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python39\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\Anurag Dutta\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.9_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python39\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import DataLoader, Dataset, random_split\n",
    "from torchvision import transforms\n",
    "from torch.optim import Adam\n",
    "import os\n",
    "import time\n",
    "from PIL import Image\n",
    "from sklearn.metrics import accuracy_score, precision_recall_fscore_support, classification_report\n",
    "import numpy as np\n",
    "\n",
    "# Dataset class\n",
    "class Data_Class(Dataset):\n",
    "    def __init__(self, root_dirs, transform=None):\n",
    "        self.root_dirs = root_dirs\n",
    "        self.transform = transform\n",
    "        self.image_paths = []\n",
    "        self.labels = []\n",
    "        self.classes = sorted(os.listdir(root_dirs[0]))\n",
    "        \n",
    "        for root_dir in root_dirs:\n",
    "            for label, class_name in enumerate(self.classes):\n",
    "                class_dir = os.path.join(root_dir, class_name)\n",
    "                for img_name in os.listdir(class_dir):\n",
    "                    img_path = os.path.join(class_dir, img_name)\n",
    "                    self.image_paths.append(img_path)\n",
    "                    self.labels.append(label)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.image_paths)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        img_path = self.image_paths[idx]\n",
    "        image = Image.open(img_path).convert(\"L\")\n",
    "        label = self.labels[idx]\n",
    "\n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "\n",
    "        return image, label\n",
    "\n",
    "\n",
    "class CNNClassifier(nn.Module):\n",
    "    def __init__(self, num_classes):\n",
    "        super(CNNClassifier, self).__init__()\n",
    "\n",
    "        self.conv_layers = nn.Sequential(\n",
    "            nn.Conv2d(1, 5, kernel_size=3, stride=1, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size=2, stride=2),\n",
    "\n",
    "            nn.Conv2d(5, 25, kernel_size=3, stride=1, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "        )\n",
    "\n",
    "        self.fc_layers = nn.Sequential(\n",
    "            nn.Linear(25 * 16 * 16, 512),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.5),\n",
    "\n",
    "            nn.Linear(512, 256),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.5),\n",
    "\n",
    "            nn.Linear(256, num_classes)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.conv_layers(x)\n",
    "        x = x.view(x.size(0), -1)\n",
    "        x = self.fc_layers(x)\n",
    "        return x\n",
    "\n",
    "image_size = 64\n",
    "num_classes = 9 # num_classes will change as per the number of output class of the dataset being considered. \n",
    "\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize((image_size, image_size)),\n",
    "    transforms.ToTensor()\n",
    "])\n",
    "\n",
    "root_dirs = ['aug']\n",
    "dataset = Data_Class(root_dirs=root_dirs, transform=transform)\n",
    "train_size = int(0.8 * len(dataset))\n",
    "test_size = len(dataset) - train_size\n",
    "train_dataset, test_dataset = random_split(dataset, [train_size, test_size])\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=32, shuffle=False)\n",
    "\n",
    "model = CNNClassifier(num_classes=num_classes)\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "model = model.to(device)\n",
    "\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = Adam(model.parameters(), lr=1e-4)\n",
    "\n",
    "start_time = time.time()\n",
    "num_epochs = 10\n",
    "for epoch in range(num_epochs):\n",
    "    epoch_start_time = time.time()\n",
    "    model.train()\n",
    "    running_loss = 0.0\n",
    "    for images, labels in train_loader:\n",
    "        images = images.to(device)\n",
    "        labels = labels.to(device)\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(images)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        running_loss += loss.item()\n",
    "\n",
    "    epoch_loss = running_loss / len(train_loader)\n",
    "    epoch_time = time.time() - epoch_start_time\n",
    "    print(f\"Epoch [{epoch + 1}/{num_epochs}], Loss: {epoch_loss:.4f}, Time elapsed: {epoch_time:.2f} seconds\")\n",
    "\n",
    "\n",
    "total_time = time.time() - start_time\n",
    "print(f\"Training completed in: {total_time:.2f} seconds\")\n",
    "\n",
    "model.eval()\n",
    "all_labels = []\n",
    "all_predictions = []\n",
    "\n",
    "with torch.no_grad():\n",
    "    for images, labels in test_loader:\n",
    "        images = images.to(device)\n",
    "        labels = labels.to(device)\n",
    "        \n",
    "        outputs = model(images)\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        all_labels.extend(labels.cpu().numpy())\n",
    "        all_predictions.extend(predicted.cpu().numpy())\n",
    "\n",
    "all_labels = np.array(all_labels)\n",
    "all_predictions = np.array(all_predictions)\n",
    "\n",
    "accuracy = accuracy_score(all_labels, all_predictions)\n",
    "precision, recall, f1, _ = precision_recall_fscore_support(all_labels, all_predictions, average='macro')\n",
    "\n",
    "print(f'Accuracy: {accuracy:.4f}')\n",
    "print(f'Precision: {precision:.4f}')\n",
    "print(f'Recall: {recall:.4f}')\n",
    "print(f'F1 Score: {f1:.4f}')\n",
    "\n",
    "print('\\nClassification Report:')\n",
    "print(classification_report(all_labels, all_predictions, target_names=[f'Class {i}' for i in range(num_classes)]))\n",
    "\n",
    "torch.save(model.state_dict(), 'cnn_64x64.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training completed in: 322.80 seconds\n",
      "Accuracy: 0.9845\n",
      "Precision: 0.9875\n",
      "Recall: 0.9850\n",
      "F1 Score: 0.9859\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "     Class 0       1.00      0.94      0.97       221\n",
      "     Class 1       0.91      1.00      0.95       279\n",
      "     Class 2       1.00      0.96      0.98       263\n",
      "     Class 3       1.00      0.99      0.99       258\n",
      "     Class 4       1.00      1.00      1.00       221\n",
      "     Class 5       0.99      1.00      1.00       210\n",
      "     Class 6       1.00      1.00      1.00       202\n",
      "     Class 7       1.00      1.00      1.00       213\n",
      "     Class 8       0.99      0.99      0.99       191\n",
      "\n",
      "    accuracy                           0.98      2058\n",
      "   macro avg       0.99      0.98      0.99      2058\n",
      "weighted avg       0.99      0.98      0.98      2058\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['svm_64x64.pkl']"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "from torch.utils.data import DataLoader, Dataset, random_split\n",
    "from torchvision import transforms\n",
    "import os\n",
    "import time\n",
    "from PIL import Image\n",
    "from sklearn.metrics import accuracy_score, precision_recall_fscore_support, classification_report\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.pipeline import Pipeline\n",
    "import numpy as np\n",
    "\n",
    "class Data_Class(Dataset):\n",
    "    def __init__(self, root_dirs, transform=None):\n",
    "        self.root_dirs = root_dirs\n",
    "        self.transform = transform\n",
    "        self.image_paths = []\n",
    "        self.labels = []\n",
    "        self.classes = sorted(os.listdir(root_dirs[0]))\n",
    "        \n",
    "        for root_dir in root_dirs:\n",
    "            for label, class_name in enumerate(self.classes):\n",
    "                class_dir = os.path.join(root_dir, class_name)\n",
    "                for img_name in os.listdir(class_dir):\n",
    "                    img_path = os.path.join(class_dir, img_name)\n",
    "                    self.image_paths.append(img_path)\n",
    "                    self.labels.append(label)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.image_paths)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        img_path = self.image_paths[idx]\n",
    "        image = Image.open(img_path).convert(\"L\")\n",
    "        label = self.labels[idx]\n",
    "\n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "\n",
    "        return image, label\n",
    "\n",
    "image_size = 64\n",
    "num_classes = 9 # num_classes will change as per the number of output class of the dataset being considered. \n",
    "\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize((image_size, image_size)),\n",
    "    transforms.ToTensor()\n",
    "])\n",
    "\n",
    "root_dirs = ['aug']\n",
    "dataset = Data_Class(root_dirs=root_dirs, transform=transform)\n",
    "train_size = int(0.8 * len(dataset))\n",
    "test_size = len(dataset) - train_size\n",
    "train_dataset, test_dataset = random_split(dataset, [train_size, test_size])\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=32, shuffle=False)\n",
    "\n",
    "def flatten_images(loader):\n",
    "    flattened_images = []\n",
    "    labels = []\n",
    "    for images, lbls in loader:\n",
    "        images = images.view(images.size(0), -1).numpy()\n",
    "        flattened_images.append(images)\n",
    "        labels.append(lbls.numpy())\n",
    "    return np.vstack(flattened_images), np.hstack(labels)\n",
    "\n",
    "X_train, y_train = flatten_images(train_loader)\n",
    "X_test, y_test = flatten_images(test_loader)\n",
    "\n",
    "model = Pipeline([\n",
    "    ('scaler', StandardScaler()),\n",
    "    ('svm', SVC(kernel='rbf', C=1, gamma='scale', probability=True))\n",
    "])\n",
    "\n",
    "start_time = time.time()\n",
    "model.fit(X_train, y_train)\n",
    "training_time = time.time() - start_time\n",
    "\n",
    "print(f\"Training completed in: {training_time:.2f} seconds\")\n",
    "\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "precision, recall, f1, _ = precision_recall_fscore_support(y_test, y_pred, average='macro')\n",
    "\n",
    "print(f'Accuracy: {accuracy:.4f}')\n",
    "print(f'Precision: {precision:.4f}')\n",
    "print(f'Recall: {recall:.4f}')\n",
    "print(f'F1 Score: {f1:.4f}')\n",
    "\n",
    "print('\\nClassification Report:')\n",
    "print(classification_report(y_test, y_pred, target_names=[f'Class {i}' for i in range(num_classes)]))\n",
    "\n",
    "import joblib\n",
    "joblib.dump(model, 'svm_64x64.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Anurag Dutta\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.9_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python39\\site-packages\\xgboost\\sklearn.py:1395: UserWarning: `use_label_encoder` is deprecated in 1.7.0.\n",
      "  warnings.warn(\"`use_label_encoder` is deprecated in 1.7.0.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training completed in: 737.37 seconds\n",
      "Accuracy: 0.9845\n",
      "Precision: 0.9855\n",
      "Recall: 0.9858\n",
      "F1 Score: 0.9856\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "     Class 0       0.96      0.96      0.96       246\n",
      "     Class 1       0.97      0.96      0.96       271\n",
      "     Class 2       0.96      0.98      0.97       230\n",
      "     Class 3       1.00      0.98      0.99       264\n",
      "     Class 4       1.00      1.00      1.00       217\n",
      "     Class 5       1.00      1.00      1.00       206\n",
      "     Class 6       1.00      1.00      1.00       211\n",
      "     Class 7       1.00      1.00      1.00       201\n",
      "     Class 8       1.00      1.00      1.00       212\n",
      "\n",
      "    accuracy                           0.98      2058\n",
      "   macro avg       0.99      0.99      0.99      2058\n",
      "weighted avg       0.98      0.98      0.98      2058\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['xgboost_64x64.pkl']"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "from torch.utils.data import DataLoader, Dataset, random_split\n",
    "from torchvision import transforms\n",
    "import os\n",
    "import time\n",
    "from PIL import Image\n",
    "from sklearn.metrics import accuracy_score, precision_recall_fscore_support, classification_report\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.pipeline import Pipeline\n",
    "import numpy as np\n",
    "import joblib\n",
    "from xgboost import XGBClassifier\n",
    "\n",
    "class Data_Class(Dataset):\n",
    "    def __init__(self, root_dirs, transform=None):\n",
    "        self.root_dirs = root_dirs\n",
    "        self.transform = transform\n",
    "        self.image_paths = []\n",
    "        self.labels = []\n",
    "        self.classes = sorted(os.listdir(root_dirs[0]))\n",
    "        \n",
    "        for root_dir in root_dirs:\n",
    "            for label, class_name in enumerate(self.classes):\n",
    "                class_dir = os.path.join(root_dir, class_name)\n",
    "                for img_name in os.listdir(class_dir):\n",
    "                    img_path = os.path.join(class_dir, img_name)\n",
    "                    self.image_paths.append(img_path)\n",
    "                    self.labels.append(label)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.image_paths)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        img_path = self.image_paths[idx]\n",
    "        image = Image.open(img_path).convert(\"L\")\n",
    "        label = self.labels[idx]\n",
    "\n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "\n",
    "        return image, label\n",
    "\n",
    "image_size = 64\n",
    "num_classes = 9 # num_classes will change as per the number of output class of the dataset being considered. \n",
    "\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize((image_size, image_size)),\n",
    "    transforms.ToTensor()\n",
    "])\n",
    "\n",
    "root_dirs = ['aug']\n",
    "dataset = Data_Class(root_dirs=root_dirs, transform=transform)\n",
    "train_size = int(0.8 * len(dataset))\n",
    "test_size = len(dataset) - train_size\n",
    "train_dataset, test_dataset = random_split(dataset, [train_size, test_size])\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=32, shuffle=False)\n",
    "\n",
    "def flatten_images(loader):\n",
    "    flattened_images = []\n",
    "    labels = []\n",
    "    for images, lbls in loader:\n",
    "        images = images.view(images.size(0), -1).numpy()\n",
    "        flattened_images.append(images)\n",
    "        labels.append(lbls.numpy())\n",
    "    return np.vstack(flattened_images), np.hstack(labels)\n",
    "\n",
    "X_train, y_train = flatten_images(train_loader)\n",
    "X_test, y_test = flatten_images(test_loader)\n",
    "\n",
    "model = Pipeline([\n",
    "    ('scaler', StandardScaler()),\n",
    "    ('xgb', XGBClassifier(use_label_encoder=False, eval_metric='mlogloss', n_estimators=100, max_depth=6, learning_rate=0.1))\n",
    "])\n",
    "\n",
    "start_time = time.time()\n",
    "model.fit(X_train, y_train)\n",
    "training_time = time.time() - start_time\n",
    "\n",
    "print(f\"Training completed in: {training_time:.2f} seconds\")\n",
    "\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "precision, recall, f1, _ = precision_recall_fscore_support(y_test, y_pred, average='macro')\n",
    "\n",
    "print(f'Accuracy: {accuracy:.4f}')\n",
    "print(f'Precision: {precision:.4f}')\n",
    "print(f'Recall: {recall:.4f}')\n",
    "print(f'F1 Score: {f1:.4f}')\n",
    "\n",
    "print('\\nClassification Report:')\n",
    "print(classification_report(y_test, y_pred, target_names=[f'Class {i}' for i in range(num_classes)]))\n",
    "\n",
    "joblib.dump(model, 'xgboost_64x64.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training completed in: 18.06 seconds\n",
      "Accuracy: 0.9738\n",
      "Precision: 0.9765\n",
      "Recall: 0.9761\n",
      "F1 Score: 0.9762\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "     Class 0       0.93      0.92      0.93       246\n",
      "     Class 1       0.91      0.94      0.93       269\n",
      "     Class 2       0.98      0.95      0.96       256\n",
      "     Class 3       0.99      0.99      0.99       232\n",
      "     Class 4       1.00      0.99      0.99       231\n",
      "     Class 5       0.99      1.00      1.00       223\n",
      "     Class 6       1.00      1.00      1.00       207\n",
      "     Class 7       1.00      1.00      1.00       209\n",
      "     Class 8       0.99      0.99      0.99       185\n",
      "\n",
      "    accuracy                           0.97      2058\n",
      "   macro avg       0.98      0.98      0.98      2058\n",
      "weighted avg       0.97      0.97      0.97      2058\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['rf_64x64.pkl']"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "from torch.utils.data import DataLoader, Dataset, random_split\n",
    "from torchvision import transforms\n",
    "import os\n",
    "import time\n",
    "from PIL import Image\n",
    "from sklearn.metrics import accuracy_score, precision_recall_fscore_support, classification_report\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.pipeline import Pipeline\n",
    "import numpy as np\n",
    "import joblib\n",
    "\n",
    "class Data_Class(Dataset):\n",
    "    def __init__(self, root_dirs, transform=None):\n",
    "        self.root_dirs = root_dirs\n",
    "        self.transform = transform\n",
    "        self.image_paths = []\n",
    "        self.labels = []\n",
    "        self.classes = sorted(os.listdir(root_dirs[0]))\n",
    "        \n",
    "        for root_dir in root_dirs:\n",
    "            for label, class_name in enumerate(self.classes):\n",
    "                class_dir = os.path.join(root_dir, class_name)\n",
    "                for img_name in os.listdir(class_dir):\n",
    "                    img_path = os.path.join(class_dir, img_name)\n",
    "                    self.image_paths.append(img_path)\n",
    "                    self.labels.append(label)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.image_paths)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        img_path = self.image_paths[idx]\n",
    "        image = Image.open(img_path).convert(\"L\")\n",
    "        label = self.labels[idx]\n",
    "\n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "\n",
    "        return image, label\n",
    "\n",
    "image_size = 64\n",
    "num_classes = 9 # num_classes will change as per the number of output class of the dataset being considered. \n",
    "\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize((image_size, image_size)),\n",
    "    transforms.ToTensor()\n",
    "])\n",
    "\n",
    "root_dirs = ['aug']\n",
    "dataset = Data_Class(root_dirs=root_dirs, transform=transform)\n",
    "train_size = int(0.8 * len(dataset))\n",
    "test_size = len(dataset) - train_size\n",
    "train_dataset, test_dataset = random_split(dataset, [train_size, test_size])\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=32, shuffle=False)\n",
    "\n",
    "def flatten_images(loader):\n",
    "    flattened_images = []\n",
    "    labels = []\n",
    "    for images, lbls in loader:\n",
    "        images = images.view(images.size(0), -1).numpy()\n",
    "        flattened_images.append(images)\n",
    "        labels.append(lbls.numpy())\n",
    "    return np.vstack(flattened_images), np.hstack(labels)\n",
    "\n",
    "X_train, y_train = flatten_images(train_loader)\n",
    "X_test, y_test = flatten_images(test_loader)\n",
    "\n",
    "model = Pipeline([\n",
    "    ('scaler', StandardScaler()),\n",
    "    ('rf', RandomForestClassifier(n_estimators=100, random_state=42))\n",
    "])\n",
    "\n",
    "start_time = time.time()\n",
    "model.fit(X_train, y_train)\n",
    "training_time = time.time() - start_time\n",
    "\n",
    "print(f\"Training completed in: {training_time:.2f} seconds\")\n",
    "\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "precision, recall, f1, _ = precision_recall_fscore_support(y_test, y_pred, average='macro')\n",
    "\n",
    "print(f'Accuracy: {accuracy:.4f}')\n",
    "print(f'Precision: {precision:.4f}')\n",
    "print(f'Recall: {recall:.4f}')\n",
    "print(f'F1 Score: {f1:.4f}')\n",
    "\n",
    "print('\\nClassification Report:')\n",
    "print(classification_report(y_test, y_pred, target_names=[f'Class {i}' for i in range(num_classes)]))\n",
    "\n",
    "joblib.dump(model, 'rf_64x64.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Anurag Dutta\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.9_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python39\\site-packages\\sklearn\\linear_model\\_logistic.py:1256: FutureWarning: 'multi_class' was deprecated in version 1.5 and will be removed in 1.7. Use OneVsRestClassifier(LogisticRegression(..)) instead. Leave it to its default value to avoid this warning.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training completed in: 18.63 seconds\n",
      "Accuracy: 0.9971\n",
      "Precision: 0.9975\n",
      "Recall: 0.9973\n",
      "F1 Score: 0.9974\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "     Class 0       0.99      0.99      0.99       249\n",
      "     Class 1       0.99      0.99      0.99       267\n",
      "     Class 2       1.00      1.00      1.00       267\n",
      "     Class 3       1.00      1.00      1.00       235\n",
      "     Class 4       1.00      1.00      1.00       230\n",
      "     Class 5       1.00      1.00      1.00       205\n",
      "     Class 6       1.00      1.00      1.00       188\n",
      "     Class 7       1.00      1.00      1.00       214\n",
      "     Class 8       1.00      1.00      1.00       203\n",
      "\n",
      "    accuracy                           1.00      2058\n",
      "   macro avg       1.00      1.00      1.00      2058\n",
      "weighted avg       1.00      1.00      1.00      2058\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['logistic_64x64.pkl']"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "from torch.utils.data import DataLoader, Dataset, random_split\n",
    "from torchvision import transforms\n",
    "import os\n",
    "import time\n",
    "from PIL import Image\n",
    "from sklearn.metrics import accuracy_score, precision_recall_fscore_support, classification_report\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.pipeline import Pipeline\n",
    "import numpy as np\n",
    "import joblib\n",
    "\n",
    "class Data_Class(Dataset):\n",
    "    def __init__(self, root_dirs, transform=None):\n",
    "        self.root_dirs = root_dirs\n",
    "        self.transform = transform\n",
    "        self.image_paths = []\n",
    "        self.labels = []\n",
    "        self.classes = sorted(os.listdir(root_dirs[0]))\n",
    "        \n",
    "        for root_dir in root_dirs:\n",
    "            for label, class_name in enumerate(self.classes):\n",
    "                class_dir = os.path.join(root_dir, class_name)\n",
    "                for img_name in os.listdir(class_dir):\n",
    "                    img_path = os.path.join(class_dir, img_name)\n",
    "                    self.image_paths.append(img_path)\n",
    "                    self.labels.append(label)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.image_paths)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        img_path = self.image_paths[idx]\n",
    "        image = Image.open(img_path).convert(\"L\")\n",
    "        label = self.labels[idx]\n",
    "\n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "\n",
    "        return image, label\n",
    "\n",
    "image_size = 64\n",
    "num_classes = 9 # num_classes will change as per the number of output class of the dataset being considered. \n",
    "\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize((image_size, image_size)),\n",
    "    transforms.ToTensor()\n",
    "])\n",
    "\n",
    "root_dirs = ['aug']\n",
    "dataset = Data_Class(root_dirs=root_dirs, transform=transform)\n",
    "train_size = int(0.8 * len(dataset))\n",
    "test_size = len(dataset) - train_size\n",
    "train_dataset, test_dataset = random_split(dataset, [train_size, test_size])\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=32, shuffle=False)\n",
    "\n",
    "def flatten_images(loader):\n",
    "    flattened_images = []\n",
    "    labels = []\n",
    "    for images, lbls in loader:\n",
    "        images = images.view(images.size(0), -1).numpy()\n",
    "        flattened_images.append(images)\n",
    "        labels.append(lbls.numpy())\n",
    "    return np.vstack(flattened_images), np.hstack(labels)\n",
    "\n",
    "X_train, y_train = flatten_images(train_loader)\n",
    "X_test, y_test = flatten_images(test_loader)\n",
    "\n",
    "model = Pipeline([\n",
    "    ('scaler', StandardScaler()),\n",
    "    ('logistic', LogisticRegression(max_iter=1000, multi_class='ovr'))\n",
    "])\n",
    "\n",
    "start_time = time.time()\n",
    "model.fit(X_train, y_train)\n",
    "training_time = time.time() - start_time\n",
    "\n",
    "print(f\"Training completed in: {training_time:.2f} seconds\")\n",
    "\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "precision, recall, f1, _ = precision_recall_fscore_support(y_test, y_pred, average='macro')\n",
    "\n",
    "print(f'Accuracy: {accuracy:.4f}')\n",
    "print(f'Precision: {precision:.4f}')\n",
    "print(f'Recall: {recall:.4f}')\n",
    "print(f'F1 Score: {f1:.4f}')\n",
    "\n",
    "print('\\nClassification Report:')\n",
    "print(classification_report(y_test, y_pred, target_names=[f'Class {i}' for i in range(num_classes)]))\n",
    "\n",
    "joblib.dump(model, 'logistic_64x64.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training completed in: 0.80 seconds\n",
      "Accuracy: 0.7478\n",
      "Precision: 0.8027\n",
      "Recall: 0.7719\n",
      "F1 Score: 0.7537\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "     Class 0       0.63      0.85      0.72       242\n",
      "     Class 1       1.00      0.31      0.47       257\n",
      "     Class 2       0.41      0.21      0.28       270\n",
      "     Class 3       0.48      0.89      0.62       251\n",
      "     Class 4       0.97      0.90      0.93       239\n",
      "     Class 5       0.82      1.00      0.90       220\n",
      "     Class 6       1.00      0.96      0.98       206\n",
      "     Class 7       1.00      0.96      0.98       190\n",
      "     Class 8       0.92      0.88      0.90       183\n",
      "\n",
      "    accuracy                           0.75      2058\n",
      "   macro avg       0.80      0.77      0.75      2058\n",
      "weighted avg       0.79      0.75      0.73      2058\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['naive_bayes_64x64.pkl']"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "from torch.utils.data import DataLoader, Dataset, random_split\n",
    "from torchvision import transforms\n",
    "import os\n",
    "import time\n",
    "from PIL import Image\n",
    "from sklearn.metrics import accuracy_score, precision_recall_fscore_support, classification_report\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.pipeline import Pipeline\n",
    "import numpy as np\n",
    "import joblib\n",
    "\n",
    "class Data_Class(Dataset):\n",
    "    def __init__(self, root_dirs, transform=None):\n",
    "        self.root_dirs = root_dirs\n",
    "        self.transform = transform\n",
    "        self.image_paths = []\n",
    "        self.labels = []\n",
    "        self.classes = sorted(os.listdir(root_dirs[0]))\n",
    "        \n",
    "        for root_dir in root_dirs:\n",
    "            for label, class_name in enumerate(self.classes):\n",
    "                class_dir = os.path.join(root_dir, class_name)\n",
    "                for img_name in os.listdir(class_dir):\n",
    "                    img_path = os.path.join(class_dir, img_name)\n",
    "                    self.image_paths.append(img_path)\n",
    "                    self.labels.append(label)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.image_paths)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        img_path = self.image_paths[idx]\n",
    "        image = Image.open(img_path).convert(\"L\")\n",
    "        label = self.labels[idx]\n",
    "\n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "\n",
    "        return image, label\n",
    "\n",
    "image_size = 64\n",
    "num_classes = 9 # num_classes will change as per the number of output class of the dataset being considered. \n",
    "\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize((image_size, image_size)),\n",
    "    transforms.ToTensor()\n",
    "])\n",
    "\n",
    "root_dirs = ['aug']\n",
    "dataset = Data_Class(root_dirs=root_dirs, transform=transform)\n",
    "train_size = int(0.8 * len(dataset))\n",
    "test_size = len(dataset) - train_size\n",
    "train_dataset, test_dataset = random_split(dataset, [train_size, test_size])\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=32, shuffle=False)\n",
    "\n",
    "def flatten_images(loader):\n",
    "    flattened_images = []\n",
    "    labels = []\n",
    "    for images, lbls in loader:\n",
    "        images = images.view(images.size(0), -1).numpy()\n",
    "        flattened_images.append(images)\n",
    "        labels.append(lbls.numpy())\n",
    "    return np.vstack(flattened_images), np.hstack(labels)\n",
    "\n",
    "X_train, y_train = flatten_images(train_loader)\n",
    "X_test, y_test = flatten_images(test_loader)\n",
    "\n",
    "model = Pipeline([\n",
    "    ('scaler', StandardScaler()),\n",
    "    ('nb', GaussianNB())\n",
    "])\n",
    "\n",
    "start_time = time.time()\n",
    "model.fit(X_train, y_train)\n",
    "training_time = time.time() - start_time\n",
    "\n",
    "print(f\"Training completed in: {training_time:.2f} seconds\")\n",
    "\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "precision, recall, f1, _ = precision_recall_fscore_support(y_test, y_pred, average='macro')\n",
    "\n",
    "print(f'Accuracy: {accuracy:.4f}')\n",
    "print(f'Precision: {precision:.4f}')\n",
    "print(f'Recall: {recall:.4f}')\n",
    "print(f'F1 Score: {f1:.4f}')\n",
    "\n",
    "print('\\nClassification Report:')\n",
    "print(classification_report(y_test, y_pred, target_names=[f'Class {i}' for i in range(num_classes)]))\n",
    "\n",
    "joblib.dump(model, 'naive_bayes_64x64.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training completed in: 16.09 seconds\n",
      "Accuracy: 0.8571\n",
      "Precision: 0.8700\n",
      "Recall: 0.8680\n",
      "F1 Score: 0.8685\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "     Class 0       0.67      0.67      0.67       233\n",
      "     Class 1       0.70      0.71      0.71       286\n",
      "     Class 2       0.67      0.74      0.71       233\n",
      "     Class 3       0.89      0.80      0.84       258\n",
      "     Class 4       0.97      0.99      0.98       223\n",
      "     Class 5       0.98      0.96      0.97       204\n",
      "     Class 6       1.00      1.00      1.00       211\n",
      "     Class 7       0.99      1.00      0.99       210\n",
      "     Class 8       0.96      0.95      0.95       200\n",
      "\n",
      "    accuracy                           0.86      2058\n",
      "   macro avg       0.87      0.87      0.87      2058\n",
      "weighted avg       0.86      0.86      0.86      2058\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['dt_64x64.pkl']"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "from torch.utils.data import DataLoader, Dataset, random_split\n",
    "from torchvision import transforms\n",
    "import os\n",
    "import time\n",
    "from PIL import Image\n",
    "from sklearn.metrics import accuracy_score, precision_recall_fscore_support, classification_report\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.pipeline import Pipeline\n",
    "import numpy as np\n",
    "import joblib\n",
    "\n",
    "class Data_Class(Dataset):\n",
    "    def __init__(self, root_dirs, transform=None):\n",
    "        self.root_dirs = root_dirs\n",
    "        self.transform = transform\n",
    "        self.image_paths = []\n",
    "        self.labels = []\n",
    "        self.classes = sorted(os.listdir(root_dirs[0]))\n",
    "        \n",
    "        for root_dir in root_dirs:\n",
    "            for label, class_name in enumerate(self.classes):\n",
    "                class_dir = os.path.join(root_dir, class_name)\n",
    "                for img_name in os.listdir(class_dir):\n",
    "                    img_path = os.path.join(class_dir, img_name)\n",
    "                    self.image_paths.append(img_path)\n",
    "                    self.labels.append(label)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.image_paths)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        img_path = self.image_paths[idx]\n",
    "        image = Image.open(img_path).convert(\"L\")\n",
    "        label = self.labels[idx]\n",
    "\n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "\n",
    "        return image, label\n",
    "\n",
    "image_size = 64\n",
    "num_classes = 9 # num_classes will change as per the number of output class of the dataset being considered. \n",
    "\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize((image_size, image_size)),\n",
    "    transforms.ToTensor()\n",
    "])\n",
    "\n",
    "root_dirs = ['aug']\n",
    "dataset = Data_Class(root_dirs=root_dirs, transform=transform)\n",
    "train_size = int(0.8 * len(dataset))\n",
    "test_size = len(dataset) - train_size\n",
    "train_dataset, test_dataset = random_split(dataset, [train_size, test_size])\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=32, shuffle=False)\n",
    "\n",
    "def flatten_images(loader):\n",
    "    flattened_images = []\n",
    "    labels = []\n",
    "    for images, lbls in loader:\n",
    "        images = images.view(images.size(0), -1).numpy()\n",
    "        flattened_images.append(images)\n",
    "        labels.append(lbls.numpy())\n",
    "    return np.vstack(flattened_images), np.hstack(labels)\n",
    "\n",
    "X_train, y_train = flatten_images(train_loader)\n",
    "X_test, y_test = flatten_images(test_loader)\n",
    "\n",
    "model = Pipeline([\n",
    "    ('scaler', StandardScaler()),\n",
    "    ('dt', DecisionTreeClassifier())\n",
    "])\n",
    "\n",
    "start_time = time.time()\n",
    "model.fit(X_train, y_train)\n",
    "training_time = time.time() - start_time\n",
    "\n",
    "print(f\"Training completed in: {training_time:.2f} seconds\")\n",
    "\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "precision, recall, f1, _ = precision_recall_fscore_support(y_test, y_pred, average='macro')\n",
    "\n",
    "print(f'Accuracy: {accuracy:.4f}')\n",
    "print(f'Precision: {precision:.4f}')\n",
    "print(f'Recall: {recall:.4f}')\n",
    "print(f'F1 Score: {f1:.4f}')\n",
    "\n",
    "print('\\nClassification Report:')\n",
    "print(classification_report(y_test, y_pred, target_names=[f'Class {i}' for i in range(num_classes)]))\n",
    "\n",
    "joblib.dump(model, 'dt_64x64.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/10], Loss: 0.3876, Time elapsed: 166.93 seconds\n",
      "Epoch [2/10], Loss: 0.0443, Time elapsed: 215.32 seconds\n",
      "Epoch [3/10], Loss: 0.0159, Time elapsed: 234.99 seconds\n",
      "Epoch [4/10], Loss: 0.0077, Time elapsed: 293.57 seconds\n",
      "Epoch [5/10], Loss: 0.0059, Time elapsed: 251.94 seconds\n",
      "Epoch [6/10], Loss: 0.0068, Time elapsed: 221.33 seconds\n",
      "Epoch [7/10], Loss: 0.0083, Time elapsed: 272.43 seconds\n",
      "Epoch [8/10], Loss: 0.0016, Time elapsed: 279.28 seconds\n",
      "Epoch [9/10], Loss: 0.0002, Time elapsed: 265.09 seconds\n",
      "Epoch [10/10], Loss: 0.0001, Time elapsed: 237.29 seconds\n",
      "Training completed in: 2438.17 seconds\n",
      "Accuracy: 0.9976, Precision: 0.9978, Recall: 0.9978, F1 Score: 0.9978\n"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, confusion_matrix, ConfusionMatrixDisplay\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import torchvision.transforms as transforms\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from PIL import Image\n",
    "import os\n",
    "import math\n",
    "import seaborn as sns\n",
    "import time\n",
    "\n",
    "\n",
    "from kan_convolutional.KANLinear import KANLinear\n",
    "from kan_convolutional.KANConv import KAN_Convolutional_Layer\n",
    "from kan_convolutional import convolution \n",
    "\n",
    "import os\n",
    "from PIL import Image\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torchvision.transforms as transforms\n",
    "\n",
    "class Data_Class(Dataset):\n",
    "    def __init__(self, root_dirs, transform=None):\n",
    "        self.transform = transform\n",
    "        self.image_files = []\n",
    "        self.labels = []\n",
    "        self.class_names = []\n",
    "\n",
    "        for root_dir in root_dirs:\n",
    "            for label, subfolder in enumerate(os.listdir(root_dir)):\n",
    "                subfolder_path = os.path.join(root_dir, subfolder)\n",
    "                if os.path.isdir(subfolder_path):\n",
    "                    if subfolder not in self.class_names:\n",
    "                        self.class_names.append(subfolder)\n",
    "                    label = self.class_names.index(subfolder)\n",
    "                    for img_file in os.listdir(subfolder_path):\n",
    "                        if img_file.endswith('.png'):\n",
    "                            self.image_files.append(os.path.join(subfolder_path, img_file))\n",
    "                            self.labels.append(label)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.image_files)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        img_name = self.image_files[idx]\n",
    "        image = Image.open(img_name).convert('L')\n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "        label = self.labels[idx]\n",
    "        return image, label\n",
    "\n",
    "    def get_class_names(self):\n",
    "        return self.class_names\n",
    "\n",
    "root_dirs = [\n",
    "    \"aug\"\n",
    "]\n",
    "\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize((64, 64)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.5,), (0.5,))\n",
    "])\n",
    "\n",
    "dataset = Data_Class(root_dirs=root_dirs, transform=transform)\n",
    "train_size = int(0.8 * len(dataset))\n",
    "test_size = len(dataset) - train_size\n",
    "train_dataset, test_dataset = torch.utils.data.random_split(dataset, [train_size, test_size])\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=64, shuffle=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=64, shuffle=False)\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "class BasicResNetBlock(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels, stride=1):\n",
    "        super(BasicResNetBlock, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(in_channels, out_channels, kernel_size=3, stride=stride, padding=1)\n",
    "        self.bn1 = nn.BatchNorm2d(out_channels)\n",
    "        self.conv2 = nn.Conv2d(out_channels, out_channels, kernel_size=3, padding=1)\n",
    "        self.bn2 = nn.BatchNorm2d(out_channels)\n",
    "\n",
    "        self.skip_connection = nn.Sequential()\n",
    "        if stride != 1 or in_channels != out_channels:\n",
    "            self.skip_connection = nn.Sequential(\n",
    "                nn.Conv2d(in_channels, out_channels, kernel_size=1, stride=stride),\n",
    "                nn.BatchNorm2d(out_channels)\n",
    "            )\n",
    "\n",
    "    def forward(self, x):\n",
    "        residual = self.skip_connection(x)\n",
    "        x = F.relu(self.bn1(self.conv1(x)))\n",
    "        x = self.bn2(self.conv2(x))\n",
    "        x += residual\n",
    "        x = F.relu(x)\n",
    "        return x\n",
    "\n",
    "\n",
    "class SuperResidualKAN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(SuperResidualKAN, self).__init__()\n",
    "\n",
    "        # Replace Conv2d layers with ResNet blocks\n",
    "        self.resnet_block1 = BasicResNetBlock(1, 5)\n",
    "        self.resnet_block2 = BasicResNetBlock(5, 25)\n",
    "\n",
    "        self.maxpool = nn.MaxPool2d(kernel_size=(2, 2))\n",
    "\n",
    "        self.flatten = nn.Flatten()\n",
    "\n",
    "        self.kan1 = KANLinear(\n",
    "            in_features=6400,\n",
    "            out_features=256,\n",
    "            grid_size=10,\n",
    "            spline_order=3,\n",
    "            scale_noise=0.01,\n",
    "            scale_base=1,\n",
    "            scale_spline=1,\n",
    "            base_activation=nn.SiLU,\n",
    "            grid_eps=0.02,\n",
    "            grid_range=[0, 1]\n",
    "        )\n",
    "\n",
    "        self.kan2 = KANLinear(\n",
    "            in_features=256,\n",
    "            out_features=9,  # Adjust for number of classes\n",
    "            grid_size=10,\n",
    "            spline_order=3,\n",
    "            scale_noise=0.01,\n",
    "            scale_base=1,\n",
    "            scale_spline=1,\n",
    "            base_activation=nn.SiLU,\n",
    "            grid_eps=0.02,\n",
    "            grid_range=[0, 1]\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.resnet_block1(x)\n",
    "        x = self.maxpool(x)\n",
    "\n",
    "        x = self.resnet_block2(x)\n",
    "        x = self.maxpool(x)\n",
    "\n",
    "        x = self.flatten(x)\n",
    "\n",
    "        x = self.kan1(x)\n",
    "\n",
    "        x = self.kan2(x)\n",
    "\n",
    "        x = F.log_softmax(x, dim=1)\n",
    "\n",
    "        return x\n",
    "\n",
    "    \n",
    "model = SuperResidualKAN()\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "start_time = time.time()\n",
    "\n",
    "for epoch in range(10): \n",
    "    epoch_start_time = time.time()\n",
    "    model.train()\n",
    "    running_loss = 0.0\n",
    "    for images, labels in train_loader:\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(images)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        running_loss += loss.item()\n",
    "\n",
    "    epoch_time = time.time() - epoch_start_time\n",
    "    print(f'Epoch [{epoch + 1}/10], Loss: {running_loss / len(train_loader):.4f}, Time elapsed: {epoch_time:.2f} seconds')\n",
    "\n",
    "total_time = time.time() - start_time\n",
    "print(f\"Training completed in: {total_time:.2f} seconds\")\n",
    "\n",
    "model.eval()\n",
    "all_preds = []\n",
    "all_labels = []\n",
    "with torch.no_grad():\n",
    "    for images, labels in test_loader:\n",
    "        outputs = model(images)\n",
    "        _, preds = torch.max(outputs, 1)\n",
    "        all_preds.extend(preds.numpy())\n",
    "        all_labels.extend(labels.numpy())\n",
    "\n",
    "all_preds = np.array(all_preds)\n",
    "all_labels = np.array(all_labels)\n",
    "\n",
    "accuracy = accuracy_score(all_labels, all_preds)\n",
    "precision = precision_score(all_labels, all_preds, average='macro')\n",
    "recall = recall_score(all_labels, all_preds, average='macro')\n",
    "f1 = f1_score(all_labels, all_preds, average='macro')\n",
    "\n",
    "print(f'Accuracy: {accuracy:.4f}, Precision: {precision:.4f}, Recall: {recall:.4f}, F1 Score: {f1:.4f}')\n",
    "torch.save(model.state_dict(), 'super_kan_r_64x64.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/10], Loss: 0.3621, Time elapsed: 107.67 seconds\n",
      "Epoch [2/10], Loss: 0.0584, Time elapsed: 106.89 seconds\n",
      "Epoch [3/10], Loss: 0.0243, Time elapsed: 128.32 seconds\n",
      "Epoch [4/10], Loss: 0.0104, Time elapsed: 126.98 seconds\n",
      "Epoch [5/10], Loss: 0.0169, Time elapsed: 114.97 seconds\n",
      "Epoch [6/10], Loss: 0.0055, Time elapsed: 120.25 seconds\n",
      "Epoch [7/10], Loss: 0.0013, Time elapsed: 123.09 seconds\n",
      "Epoch [8/10], Loss: 0.0005, Time elapsed: 127.54 seconds\n",
      "Epoch [9/10], Loss: 0.0003, Time elapsed: 134.35 seconds\n",
      "Epoch [10/10], Loss: 0.0003, Time elapsed: 142.21 seconds\n",
      "Training completed in: 1232.27 seconds\n",
      "Accuracy: 0.9917, Precision: 0.9924, Recall: 0.9925, F1 Score: 0.9925\n"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, confusion_matrix, ConfusionMatrixDisplay\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import torchvision.transforms as transforms\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from PIL import Image\n",
    "import os\n",
    "import math\n",
    "import seaborn as sns\n",
    "import time\n",
    "\n",
    "\n",
    "from kan_convolutional.KANLinear import KANLinear\n",
    "from kan_convolutional.KANConv import KAN_Convolutional_Layer\n",
    "from kan_convolutional import convolution \n",
    "\n",
    "import os\n",
    "from PIL import Image\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torchvision.transforms as transforms\n",
    "\n",
    "class Data_Class(Dataset):\n",
    "    def __init__(self, root_dirs, transform=None):\n",
    "        self.transform = transform\n",
    "        self.image_files = []\n",
    "        self.labels = []\n",
    "        self.class_names = []\n",
    "\n",
    "        for root_dir in root_dirs:\n",
    "            for label, subfolder in enumerate(os.listdir(root_dir)):\n",
    "                subfolder_path = os.path.join(root_dir, subfolder)\n",
    "                if os.path.isdir(subfolder_path):\n",
    "                    if subfolder not in self.class_names:\n",
    "                        self.class_names.append(subfolder)\n",
    "                    label = self.class_names.index(subfolder)\n",
    "                    for img_file in os.listdir(subfolder_path):\n",
    "                        if img_file.endswith('.png'):\n",
    "                            self.image_files.append(os.path.join(subfolder_path, img_file))\n",
    "                            self.labels.append(label)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.image_files)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        img_name = self.image_files[idx]\n",
    "        image = Image.open(img_name).convert('L')\n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "        label = self.labels[idx]\n",
    "        return image, label\n",
    "\n",
    "    def get_class_names(self):\n",
    "        return self.class_names\n",
    "\n",
    "root_dirs = [\n",
    "    \"aug\"\n",
    "]\n",
    "\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize((64, 64)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.5,), (0.5,))\n",
    "])\n",
    "\n",
    "dataset = Data_Class(root_dirs=root_dirs, transform=transform)\n",
    "train_size = int(0.8 * len(dataset))\n",
    "test_size = len(dataset) - train_size\n",
    "train_dataset, test_dataset = torch.utils.data.random_split(dataset, [train_size, test_size])\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=64, shuffle=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=64, shuffle=False)\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "class BasicResNetBlock(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels, stride=1):\n",
    "        super(BasicResNetBlock, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(in_channels, out_channels, kernel_size=3, stride=stride, padding=1)\n",
    "        self.bn1 = nn.BatchNorm2d(out_channels)\n",
    "        self.conv2 = nn.Conv2d(out_channels, out_channels, kernel_size=3, padding=1)\n",
    "        self.bn2 = nn.BatchNorm2d(out_channels)\n",
    "\n",
    "        self.skip_connection = nn.Sequential()\n",
    "        if stride != 1 or in_channels != out_channels:\n",
    "            self.skip_connection = nn.Sequential(\n",
    "                nn.Conv2d(in_channels, out_channels, kernel_size=1, stride=stride),\n",
    "                nn.BatchNorm2d(out_channels)\n",
    "            )\n",
    "\n",
    "    def forward(self, x):\n",
    "        residual = self.skip_connection(x)\n",
    "        x = F.relu(self.bn1(self.conv1(x)))\n",
    "        x = self.bn2(self.conv2(x))\n",
    "        x += residual\n",
    "        x = F.relu(x)\n",
    "        return x\n",
    "\n",
    "\n",
    "class NormalizedResidualKAN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(NormalizedResidualKAN, self).__init__()\n",
    "        \n",
    "        self.resnet_block1 = BasicResNetBlock(1, 5)\n",
    "        self.bn1 = nn.BatchNorm2d(5)\n",
    "        \n",
    "        self.resnet_block2 = BasicResNetBlock(5, 25)\n",
    "        self.bn2 = nn.BatchNorm2d(25)\n",
    "\n",
    "        self.maxpool = nn.MaxPool2d(kernel_size=(2, 2))\n",
    "\n",
    "        self.flatten = nn.Flatten()\n",
    "\n",
    "        self.kan1 = KANLinear(\n",
    "            in_features=25 * 16 * 16,\n",
    "            out_features=9, # out_features will change as per the number of output class of the dataset being considered. \n",
    "            grid_size=10,\n",
    "            spline_order=3,\n",
    "            scale_noise=0.01,\n",
    "            scale_base=1,\n",
    "            scale_spline=1,\n",
    "            base_activation=nn.SiLU,\n",
    "            grid_eps=0.02,\n",
    "            grid_range=[0, 1]\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = F.relu(self.bn1(self.resnet_block1(x)))\n",
    "        x = self.maxpool(x)\n",
    "        \n",
    "        x = F.relu(self.bn2(self.resnet_block2(x)))\n",
    "        x = self.maxpool(x)\n",
    "        \n",
    "        x = self.flatten(x)\n",
    "        x = self.kan1(x)\n",
    "        \n",
    "        x = F.log_softmax(x, dim=1)  \n",
    "\n",
    "        return x\n",
    "    \n",
    "model = NormalizedResidualKAN()\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "start_time = time.time()\n",
    "\n",
    "for epoch in range(10): \n",
    "    epoch_start_time = time.time()\n",
    "    model.train()\n",
    "    running_loss = 0.0\n",
    "    for images, labels in train_loader:\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(images)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        running_loss += loss.item()\n",
    "\n",
    "    epoch_time = time.time() - epoch_start_time\n",
    "    print(f'Epoch [{epoch + 1}/10], Loss: {running_loss / len(train_loader):.4f}, Time elapsed: {epoch_time:.2f} seconds')\n",
    "\n",
    "total_time = time.time() - start_time\n",
    "print(f\"Training completed in: {total_time:.2f} seconds\")\n",
    "\n",
    "model.eval()\n",
    "all_preds = []\n",
    "all_labels = []\n",
    "with torch.no_grad():\n",
    "    for images, labels in test_loader:\n",
    "        outputs = model(images)\n",
    "        _, preds = torch.max(outputs, 1)\n",
    "        all_preds.extend(preds.numpy())\n",
    "        all_labels.extend(labels.numpy())\n",
    "\n",
    "all_preds = np.array(all_preds)\n",
    "all_labels = np.array(all_labels)\n",
    "\n",
    "accuracy = accuracy_score(all_labels, all_preds)\n",
    "precision = precision_score(all_labels, all_preds, average='macro')\n",
    "recall = recall_score(all_labels, all_preds, average='macro')\n",
    "f1 = f1_score(all_labels, all_preds, average='macro')\n",
    "\n",
    "print(f'Accuracy: {accuracy:.4f}, Precision: {precision:.4f}, Recall: {recall:.4f}, F1 Score: {f1:.4f}')\n",
    "torch.save(model.state_dict(), 'kan_r_bn_64x64.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/10], Loss: 0.4539, Time elapsed: 151.24 seconds\n",
      "Epoch [2/10], Loss: 0.0471, Time elapsed: 152.68 seconds\n",
      "Epoch [3/10], Loss: 0.0172, Time elapsed: 114.32 seconds\n",
      "Epoch [4/10], Loss: 0.0188, Time elapsed: 105.62 seconds\n",
      "Epoch [5/10], Loss: 0.0083, Time elapsed: 104.32 seconds\n",
      "Epoch [6/10], Loss: 0.0038, Time elapsed: 106.83 seconds\n",
      "Epoch [7/10], Loss: 0.0025, Time elapsed: 98.95 seconds\n",
      "Epoch [8/10], Loss: 0.0005, Time elapsed: 99.93 seconds\n",
      "Epoch [9/10], Loss: 0.0004, Time elapsed: 101.76 seconds\n",
      "Epoch [10/10], Loss: 0.0003, Time elapsed: 99.16 seconds\n",
      "Training completed in: 1134.82 seconds\n",
      "Accuracy: 0.9966, Precision: 0.9969, Recall: 0.9967, F1 Score: 0.9968\n"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, confusion_matrix, ConfusionMatrixDisplay\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import torchvision.transforms as transforms\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from PIL import Image\n",
    "import os\n",
    "import math\n",
    "import seaborn as sns\n",
    "import time\n",
    "\n",
    "\n",
    "from kan_convolutional.KANLinear import KANLinear\n",
    "from kan_convolutional.KANConv import KAN_Convolutional_Layer\n",
    "from kan_convolutional import convolution \n",
    "\n",
    "\n",
    "\n",
    "import os\n",
    "from PIL import Image\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torchvision.transforms as transforms\n",
    "\n",
    "class Data_Class(Dataset):\n",
    "    def __init__(self, root_dirs, transform=None):\n",
    "        self.transform = transform\n",
    "        self.image_files = []\n",
    "        self.labels = []\n",
    "        self.class_names = []\n",
    "\n",
    "        for root_dir in root_dirs:\n",
    "            for label, subfolder in enumerate(os.listdir(root_dir)):\n",
    "                subfolder_path = os.path.join(root_dir, subfolder)\n",
    "                if os.path.isdir(subfolder_path):\n",
    "                    if subfolder not in self.class_names:\n",
    "                        self.class_names.append(subfolder)\n",
    "                    label = self.class_names.index(subfolder)\n",
    "                    for img_file in os.listdir(subfolder_path):\n",
    "                        if img_file.endswith('.png'):\n",
    "                            self.image_files.append(os.path.join(subfolder_path, img_file))\n",
    "                            self.labels.append(label)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.image_files)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        img_name = self.image_files[idx]\n",
    "        image = Image.open(img_name).convert('L')\n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "        label = self.labels[idx]\n",
    "        return image, label\n",
    "\n",
    "    def get_class_names(self):\n",
    "        return self.class_names\n",
    "\n",
    "root_dirs = [\n",
    "    \"aug\"\n",
    "]\n",
    "\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize((64, 64)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.5,), (0.5,))\n",
    "])\n",
    "\n",
    "dataset = Data_Class(root_dirs=root_dirs, transform=transform)\n",
    "train_size = int(0.8 * len(dataset))\n",
    "test_size = len(dataset) - train_size\n",
    "train_dataset, test_dataset = torch.utils.data.random_split(dataset, [train_size, test_size])\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=64, shuffle=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=64, shuffle=False)\n",
    "\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "\n",
    "class BasicResNetBlock(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels, stride=1):\n",
    "        super(BasicResNetBlock, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(in_channels, out_channels, kernel_size=3, stride=stride, padding=1)\n",
    "        self.bn1 = nn.BatchNorm2d(out_channels)\n",
    "        self.conv2 = nn.Conv2d(out_channels, out_channels, kernel_size=3, padding=1)\n",
    "        self.bn2 = nn.BatchNorm2d(out_channels)\n",
    "\n",
    "        self.skip_connection = nn.Sequential()\n",
    "        if stride != 1 or in_channels != out_channels:\n",
    "            self.skip_connection = nn.Sequential(\n",
    "                nn.Conv2d(in_channels, out_channels, kernel_size=1, stride=stride),\n",
    "                nn.BatchNorm2d(out_channels)\n",
    "            )\n",
    "\n",
    "    def forward(self, x):\n",
    "        residual = self.skip_connection(x)\n",
    "        x = F.relu(self.bn1(self.conv1(x)))\n",
    "        x = self.bn2(self.conv2(x))\n",
    "        x += residual\n",
    "        x = F.relu(x)\n",
    "        return x\n",
    "    \n",
    "    \n",
    "class ResidualKAN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(ResidualKAN, self).__init__()\n",
    "        \n",
    "        self.resnet_block1 = BasicResNetBlock(1, 5)\n",
    "        \n",
    "        self.resnet_block2 = BasicResNetBlock(5, 25)\n",
    "\n",
    "        self.maxpool = nn.MaxPool2d(kernel_size=(2, 2))\n",
    "\n",
    "        self.flatten = nn.Flatten()\n",
    "\n",
    "        self.kan1 = KANLinear(\n",
    "            in_features=25 * 16 * 16,\n",
    "            out_features=9, # out_features will change as per the number of output class of the dataset being considered. \n",
    "            grid_size=10,\n",
    "            spline_order=3,\n",
    "            scale_noise=0.01,\n",
    "            scale_base=1,\n",
    "            scale_spline=1,\n",
    "            base_activation=nn.SiLU,\n",
    "            grid_eps=0.02,\n",
    "            grid_range=[0, 1]\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.resnet_block1(x)\n",
    "        x = self.maxpool(x)\n",
    "        \n",
    "        x = self.resnet_block2(x)\n",
    "        x = self.maxpool(x)\n",
    "        \n",
    "        x = self.flatten(x)\n",
    "        x = self.kan1(x)\n",
    "        \n",
    "        x = F.log_softmax(x, dim=1)  \n",
    "\n",
    "        return x\n",
    "    \n",
    "model = ResidualKAN()\n",
    "\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "start_time = time.time()\n",
    "\n",
    "for epoch in range(10): \n",
    "    epoch_start_time = time.time()\n",
    "    model.train()\n",
    "    running_loss = 0.0\n",
    "    for images, labels in train_loader:\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(images)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        running_loss += loss.item()\n",
    "\n",
    "    epoch_time = time.time() - epoch_start_time\n",
    "    print(f'Epoch [{epoch + 1}/10], Loss: {running_loss / len(train_loader):.4f}, Time elapsed: {epoch_time:.2f} seconds')\n",
    "\n",
    "total_time = time.time() - start_time\n",
    "print(f\"Training completed in: {total_time:.2f} seconds\")\n",
    "\n",
    "\n",
    "model.eval()\n",
    "all_preds = []\n",
    "all_labels = []\n",
    "with torch.no_grad():\n",
    "    for images, labels in test_loader:\n",
    "        outputs = model(images)\n",
    "        _, preds = torch.max(outputs, 1)\n",
    "        all_preds.extend(preds.numpy())\n",
    "        all_labels.extend(labels.numpy())\n",
    "\n",
    "all_preds = np.array(all_preds)\n",
    "all_labels = np.array(all_labels)\n",
    "\n",
    "accuracy = accuracy_score(all_labels, all_preds)\n",
    "precision = precision_score(all_labels, all_preds, average='macro')\n",
    "recall = recall_score(all_labels, all_preds, average='macro')\n",
    "f1 = f1_score(all_labels, all_preds, average='macro')\n",
    "\n",
    "print(f'Accuracy: {accuracy:.4f}, Precision: {precision:.4f}, Recall: {recall:.4f}, F1 Score: {f1:.4f}')\n",
    "torch.save(model.state_dict(), 'kan_r_64x64.pth')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
